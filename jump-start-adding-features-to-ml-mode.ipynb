{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='#306998'><center>MSDS 451 Feature Engineering</center></font></h2>\n",
    "<h2><center>Financial Machine Learning: Adding Features to the Mix</center></h2>\n",
    "<h3><center>Thomas W. Miller, August 25, 2025</center></h3>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "We again use machine learning classifiers, including tree-based ensemble boosting and bagging methods, to predict the direction of oil futures (up or down) using a number of lagged price features. In particular, we look at daily closing spot prices for [West Texas Intermediate (ticker WTI)](https://en.wikipedia.org/wiki/West_Texas_Intermediate) with lags of one to seven days, as well as features based on opening, closing, high, and low price points, and daily trading volume. \n",
    "\n",
    "Tree-based ensemble models for predicting the direction of daily returns set the stage for testing the predictive utility of additional features. The domain of potential features or leading indicators is wide, including those associated with other price series, economic indicators, international events, securities filings, analyst and news reports, and media measures. Here we explore a set of nine features defined from a range of exchange-traded funds (ETFs).\n",
    "\n",
    "The model-building process demonstrated here can be employed for any asset or portfolio of assets.\n",
    "\n",
    "The model building process involves these steps:\n",
    "\n",
    "- Define price-based features for the target asset.\n",
    "- Define binary features (Up or not Up) for other assets, economic measures, market measures, worldwide events, and media measures.\n",
    "- Fit an ensemble model to the full set of features within a time series cross-validation design using a tree-structured ensemble with hyperparameters set to their default values. Note the test set classification performance in predicting movement (Up or not Up) in the target asset.\n",
    "- Utilized randomized search across key hyperparameters to determine \"best\" settings.\n",
    "- Use a hold-out test set to evaluate model performance with \"best\" hyperparameter settings.\n",
    "- Rank the importance of features from the model evaluation, and select the best features for subsequent model development.\n",
    "- Repeat the model-building process, adding new features to the mix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Libraries\n",
    "We draw on Python packages for data manipulation and modeling. Most important are Polars, a high-performance alternative to Pandas for data manipulation, and Scikit-Learn for machine learning study design and modeling algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: graphviz in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "import os\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# datetime functions needed for filtering across DataFrames with differing time frame\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Import Python Packages for data manipulation, data pipelines, and databases\n",
    "import numpy as np\n",
    "import pyarrow # foundation for polars\n",
    "import polars as pl # DataFrame work superior to Pandas\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Display static plots directly in the notebook output \n",
    "%matplotlib inline\n",
    "# create stylized visualizations, including heat maps\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import (RandomizedSearchCV, \n",
    "                                    TimeSeriesSplit)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# utilized in all possible subsets classification work\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# needed for randomized search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# metrics in xgboost tuning and final model evaluation\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report, \n",
    "                             roc_curve, \n",
    "                             roc_auc_score,\n",
    "                             RocCurveDisplay,\n",
    "                             ConfusionMatrixDisplay,\n",
    "                             confusion_matrix,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score\n",
    "                            )\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# XGBoost Package... more complete than SciKit-Learn boosting methods\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Data\n",
    "In previous work, we retrieved price data for WTI and nine ETFs from Yahoo Finance. The code for WTI is shown in the next commented-out cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrevious work to retrieve data from Yahoo Finance had this structure for each of the ETFs in the study\\n\\nsymbol = \\'WTI\\'\\nstart_date = \\'2000-01-01\\'\\nend_date = \\'2025-08-19\\'\\n\\nticker = yf.Ticker(symbol)\\nhistorical_data = ticker.history(start = start_date, end = end_date, period = \\'1mo\\')\\nprint(historical_data)\\n\\nprint(\"type of historical_data\", type(historical_data))\\n\\nhistorical_data.to_csv(\"wti_daily_data.csv\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Previous work to retrieve data from Yahoo Finance had this structure for each of the ETFs in the study\n",
    "\n",
    "symbol = 'WTI'\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2025-08-19'\n",
    "\n",
    "ticker = yf.Ticker(symbol)\n",
    "historical_data = ticker.history(start = start_date, end = end_date, period = '1mo')\n",
    "print(historical_data)\n",
    "\n",
    "print(\"type of historical_data\", type(historical_data))\n",
    "\n",
    "historical_data.to_csv(\"wti_daily_data.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars DataFrame Development\n",
    "The following code cell demonstrates Polars use with the time series DataFrame for our selected market/ticker, WTI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'Dividends': Float64, 'StockSplits': Float64})\n"
     ]
    }
   ],
   "source": [
    "wti = pl.read_csv(\"wti_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# check the original schema\n",
    "print(wti.schema)\n",
    "\n",
    "# drop useless columns Dividends and StockSplits\n",
    "wti = wti.drop(['Dividends', 'StockSplits'])\n",
    "\n",
    "# create lag price features\n",
    "wti = wti.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "wti = wti.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "wti = wti.with_columns((pl.col('CloseLag2')).shift().alias('CloseLag3'))\n",
    "\n",
    "# create high-minus-low (HML) for day and its lags\n",
    "wti = wti.with_columns((pl.col('High') - pl.col('Low')).alias('HML'))\n",
    "wti = wti.with_columns((pl.col('HML')).shift().alias('HMLLag1'))\n",
    "wti = wti.with_columns((pl.col('HMLLag1')).shift().alias('HMLLag2'))\n",
    "wti = wti.with_columns((pl.col('HMLLag2')).shift().alias('HMLLag3'))\n",
    "\n",
    "# create a net change for the day as the open minus closing price OMC\n",
    "# also create the corresponding lag metrics\n",
    "wti = wti.with_columns((pl.col('Open') - pl.col('Close')).alias('OMC'))\n",
    "wti = wti.with_columns((pl.col('OMC')).shift().alias('OMCLag1'))\n",
    "wti = wti.with_columns((pl.col('OMCLag1')).shift().alias('OMCLag2'))\n",
    "wti = wti.with_columns((pl.col('OMCLag2')).shift().alias('OMCLag3'))\n",
    "\n",
    "# create volume lag metrics\n",
    "wti = wti.with_columns((pl.col('Volume')).shift().alias('VolumeLag1'))\n",
    "wti = wti.with_columns((pl.col('VolumeLag1')).shift().alias('VolumeLag2'))\n",
    "wti = wti.with_columns((pl.col('VolumeLag2')).shift().alias('VolumeLag3'))\n",
    "\n",
    "# compute 10-day exponential moving averages of closing prices\n",
    "# compute acround CloseLag1 to avoid any \"leakage\" in explanatory variable set\n",
    "# note also the 10-day buffer between train and test in time-series cross-validation\n",
    "wti = wti.with_columns((pl.col('CloseLag1').ewm_mean(half_life=1,ignore_nulls=True)).alias('CloseEMA2'))\n",
    "wti = wti.with_columns((pl.col('CloseLag1').ewm_mean(half_life=2,ignore_nulls=True)).alias('CloseEMA4'))\n",
    "wti = wti.with_columns((pl.col('CloseLag1').ewm_mean(half_life=4,ignore_nulls=True)).alias('CloseEMA8'))\n",
    "\n",
    "# log daily returns\n",
    "wti = wti.with_columns(np.log(pl.col('Close')/pl.col('CloseLag1')).alias('LogReturn'))\n",
    "\n",
    "# set volume features to Float64 for subsequent use in Numpy arrays\n",
    "wti = wti.with_columns(\n",
    "    pl.col('Volume').cast(pl.Float64).round(0),\n",
    "    pl.col('VolumeLag1').cast(pl.Float64).round(0),\n",
    "    pl.col('VolumeLag2').cast(pl.Float64).round(0),\n",
    "    pl.col('VolumeLag3').cast(pl.Float64).round(0),\n",
    "    )\n",
    "\n",
    "# round other features to three decimal places for reporting and subsequent analytics\n",
    "wti = wti.with_columns(\n",
    "    pl.col('Open').round(3),\n",
    "    pl.col('High').round(3),    \n",
    "    pl.col('Low').round(3),\n",
    "    pl.col('Close').round(3),      \n",
    "    pl.col('CloseLag1').round(3),\n",
    "    pl.col('CloseLag2').round(3),  \n",
    "    pl.col('CloseLag3').round(3),\n",
    "    pl.col('HML').round(3),  \n",
    "    pl.col('HMLLag1').round(3),\n",
    "    pl.col('HMLLag2').round(3),  \n",
    "    pl.col('HMLLag3').round(3),\n",
    "    pl.col('OMC').round(3),  \n",
    "    pl.col('OMCLag1').round(3),\n",
    "    pl.col('OMCLag2').round(3),  \n",
    "    pl.col('OMCLag3').round(3), \n",
    "    pl.col('CloseEMA2').round(3),\n",
    "    pl.col('CloseEMA4').round(3), \n",
    "    pl.col('CloseEMA8').round(3))\n",
    "    \n",
    "# no correction for class imbalance in this analysis\n",
    "# define binary target/response 1 = market price up since previous day, 0 = even or down \n",
    "wti = wti.with_columns(pl.when(pl.col('LogReturn')>0).then(pl.lit(1)).otherwise(pl.lit(0)).alias('Target'))\n",
    "\n",
    "# save to external comma-delimited text file for checking calculations in Excel\n",
    "wti.write_csv(\"wti-with-computed-features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics for Price Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['statistic', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'CloseLag3', 'HML', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMC', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'LogReturn', 'Target']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌────────────┬──────────┬─────────────────────────┬─────────────────────┬─────────────────────┬───────────┬────────────────────┐\n",
      "│ column     ┆ column_0 ┆ column_2                ┆ column_3            ┆ column_4            ┆ column_6  ┆ column_8           │\n",
      "╞════════════╪══════════╪═════════════════════════╪═════════════════════╪═════════════════════╪═══════════╪════════════════════╡\n",
      "│ statistic  ┆ count    ┆ mean                    ┆ std                 ┆ min                 ┆ 50%       ┆ max                │\n",
      "│ Open       ┆ 5169.0   ┆ 9.888208357515962       ┆ 8.24379751138907    ┆ 1.105               ┆ 6.597     ┆ 44.596             │\n",
      "│ High       ┆ 5169.0   ┆ 10.104958405881215      ┆ 8.390030911332957   ┆ 1.145               ┆ 6.784     ┆ 44.626             │\n",
      "│ Low        ┆ 5169.0   ┆ 9.646586767266395       ┆ 8.068196720476312   ┆ 1.028               ┆ 6.4       ┆ 43.235             │\n",
      "│ Close      ┆ 5169.0   ┆ 9.871213774424453       ┆ 8.228563569925154   ┆ 1.047               ┆ 6.592     ┆ 44.172             │\n",
      "│ Volume     ┆ 5169.0   ┆ 1748263.726059199       ┆ 1829939.6046243927  ┆ 34700.0             ┆ 1177400.0 ┆ 40429700.0         │\n",
      "│ CloseLag1  ┆ 5169.0   ┆ 9.873441671503192       ┆ 8.22790431775934    ┆ 1.047               ┆ 6.592     ┆ 44.172             │\n",
      "│ CloseLag2  ┆ 5169.0   ┆ 9.87565660669375        ┆ 8.227255386280119   ┆ 1.047               ┆ 6.592     ┆ 44.172             │\n",
      "│ CloseLag3  ┆ 5169.0   ┆ 9.877919326755658       ┆ 8.226617508094625   ┆ 1.047               ┆ 6.592     ┆ 44.172             │\n",
      "│ HML        ┆ 5169.0   ┆ 0.4583662217063263      ┆ 0.4387466968956287  ┆ 0.029               ┆ 0.327     ┆ 4.129              │\n",
      "│ HMLLag1    ┆ 5169.0   ┆ 0.4583936931708261      ┆ 0.4387280728986695  ┆ 0.029               ┆ 0.327     ┆ 4.129              │\n",
      "│ HMLLag2    ┆ 5169.0   ┆ 0.45853685432385377     ┆ 0.43871551870478587 ┆ 0.029               ┆ 0.327     ┆ 4.129              │\n",
      "│ HMLLag3    ┆ 5169.0   ┆ 0.4587094215515574      ┆ 0.43873022336223927 ┆ 0.029               ┆ 0.327     ┆ 4.129              │\n",
      "│ OMC        ┆ 5169.0   ┆ 0.016985683884697237    ┆ 0.3799556671580719  ┆ -3.223              ┆ 0.01      ┆ 3.705              │\n",
      "│ OMCLag1    ┆ 5169.0   ┆ 0.016974656606693762    ┆ 0.3799555359557333  ┆ -3.223              ┆ 0.01      ┆ 3.705              │\n",
      "│ OMCLag2    ┆ 5169.0   ┆ 0.01702050686786613     ┆ 0.3799653728485099  ┆ -3.223              ┆ 0.01      ┆ 3.705              │\n",
      "│ OMCLag3    ┆ 5169.0   ┆ 0.01715302766492551     ┆ 0.3800928215711145  ┆ -3.223              ┆ 0.01      ┆ 3.705              │\n",
      "│ VolumeLag1 ┆ 5169.0   ┆ 1748148.5974076223      ┆ 1829989.5770774593  ┆ 34700.0             ┆ 1176900.0 ┆ 40429700.0         │\n",
      "│ VolumeLag2 ┆ 5169.0   ┆ 1748359.3538402012      ┆ 1829930.1201336666  ┆ 34700.0             ┆ 1177400.0 ┆ 40429700.0         │\n",
      "│ VolumeLag3 ┆ 5169.0   ┆ 1750131.4954536662      ┆ 1833301.7931244925  ┆ 34700.0             ┆ 1178000.0 ┆ 40429700.0         │\n",
      "│ CloseEMA2  ┆ 5169.0   ┆ 9.875673437802282       ┆ 8.219729461746063   ┆ 1.111               ┆ 6.614     ┆ 43.432             │\n",
      "│ CloseEMA4  ┆ 5169.0   ┆ 9.878829560843492       ┆ 8.210186049750966   ┆ 1.136               ┆ 6.624     ┆ 43.018             │\n",
      "│ CloseEMA8  ┆ 5169.0   ┆ 9.885304314180692       ┆ 8.190856957522218   ┆ 1.157               ┆ 6.649     ┆ 42.696             │\n",
      "│ LogReturn  ┆ 5169.0   ┆ -0.00039874914065335176 ┆ 0.04178042201340917 ┆ -0.2644790687687591 ┆ 0.0       ┆ 0.3488180995786815 │\n",
      "│ Target     ┆ 5169.0   ┆ 0.4778487134842329      ┆ 0.4995574042820073  ┆ 0.0                 ┆ 0.0       ┆ 1.0                │\n",
      "└────────────┴──────────┴─────────────────────────┴─────────────────────┴─────────────────────┴───────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with null values such as the initial lag rows\n",
    "wti = wti.drop_nulls()\n",
    "\n",
    "# Descriptive statistics\n",
    "wtiStatistics = wti.drop('Date').describe()\n",
    "\n",
    "print(wtiStatistics.columns)\n",
    "\n",
    "wtiStatisticsToPrint = wtiStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_7'])\n",
    "\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(wtiStatisticsToPrint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Feature List Defined on WTI Pricing Alone \n",
    "Features or explanatory variables, also known as an independent variables, are used to predict the values of target variables. The initial list of featrues includes the price-based features defined above, everything except the continuous response **LogReturn** if we wanted to employ regression and the binary response **Target** for classification, which is the focus of this project. This complete feature list is used in evaluating all methods.\n",
    "\n",
    "We retain Date and Target at this point... Date is needed to select across WTI and the many ETFs. Target is needed as the response in training. These will be dropped from the training features set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>CloseLag1</th><th>CloseLag2</th><th>CloseLag3</th><th>HMLLag1</th><th>HMLLag2</th><th>HMLLag3</th><th>OMCLag1</th><th>OMCLag2</th><th>OMCLag3</th><th>VolumeLag1</th><th>VolumeLag2</th><th>VolumeLag3</th><th>CloseEMA2</th><th>CloseEMA4</th><th>CloseEMA8</th><th>Target</th></tr><tr><td>datetime[μs, UTC]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td></tr></thead><tbody><tr><td>2005-02-02 05:00:00 UTC</td><td>13.196</td><td>13.189</td><td>13.406</td><td>0.232</td><td>0.79</td><td>0.942</td><td>-0.007</td><td>0.217</td><td>0.725</td><td>656500.0</td><td>1.7768e6</td><td>9.8135e6</td><td>13.224</td><td>13.241</td><td>13.252</td><td>0</td></tr><tr><td>2005-02-03 05:00:00 UTC</td><td>13.196</td><td>13.196</td><td>13.189</td><td>0.152</td><td>0.232</td><td>0.79</td><td>0.029</td><td>-0.007</td><td>0.217</td><td>265300.0</td><td>656500.0</td><td>1.7768e6</td><td>13.209</td><td>13.224</td><td>13.234</td><td>1</td></tr><tr><td>2005-02-04 05:00:00 UTC</td><td>13.225</td><td>13.196</td><td>13.196</td><td>0.087</td><td>0.152</td><td>0.232</td><td>0.0</td><td>0.029</td><td>-0.007</td><td>303200.0</td><td>265300.0</td><td>656500.0</td><td>13.217</td><td>13.224</td><td>13.232</td><td>0</td></tr><tr><td>2005-02-07 05:00:00 UTC</td><td>13.189</td><td>13.225</td><td>13.196</td><td>0.275</td><td>0.087</td><td>0.152</td><td>0.072</td><td>0.0</td><td>0.029</td><td>361100.0</td><td>303200.0</td><td>265300.0</td><td>13.203</td><td>13.212</td><td>13.221</td><td>1</td></tr><tr><td>2005-02-08 05:00:00 UTC</td><td>13.218</td><td>13.189</td><td>13.225</td><td>0.196</td><td>0.275</td><td>0.087</td><td>0.152</td><td>0.072</td><td>0.0</td><td>161900.0</td><td>361100.0</td><td>303200.0</td><td>13.211</td><td>13.214</td><td>13.221</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 17)\n",
       "┌─────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
       "│ Date        ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA8 ┆ Target │\n",
       "│ ---         ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---    │\n",
       "│ datetime[μs ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32    │\n",
       "│ , UTC]      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "╞═════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
       "│ 2005-02-02  ┆ 13.196    ┆ 13.189    ┆ 13.406    ┆ … ┆ 13.224    ┆ 13.241    ┆ 13.252    ┆ 0      │\n",
       "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ 2005-02-03  ┆ 13.196    ┆ 13.196    ┆ 13.189    ┆ … ┆ 13.209    ┆ 13.224    ┆ 13.234    ┆ 1      │\n",
       "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ 2005-02-04  ┆ 13.225    ┆ 13.196    ┆ 13.196    ┆ … ┆ 13.217    ┆ 13.224    ┆ 13.232    ┆ 0      │\n",
       "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ 2005-02-07  ┆ 13.189    ┆ 13.225    ┆ 13.196    ┆ … ┆ 13.203    ┆ 13.212    ┆ 13.221    ┆ 1      │\n",
       "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ 2005-02-08  ┆ 13.218    ┆ 13.189    ┆ 13.225    ┆ … ┆ 13.211    ┆ 13.214    ┆ 13.221    ┆ 0      │\n",
       "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
       "└─────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Features for the Model, exclude current day price variables ... no \"leakage\"\n",
    "# note for moving averages, we have excluded the current day, and provide a 10-day gap\n",
    "# so these may be included in the set \n",
    "wti = wti.drop(['LogReturn', 'Open', 'High', 'Low', 'Close', 'Volume', 'HML', 'OMC'])\n",
    "wti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data for Nine Exchange Traded Funds\n",
    "The following code cells read data from nine exchange-traded funds (ETFs) selected to cover a wide range of asset classes. All of these funds have about a billion or more assets under management (AUM). We note the range of dates covered in each ETF DataFrame. Later we will ensure that the same date ranges are covered by WTI and the nine ETFs. Beginning dates vary, but all time series end on August 19, 2025. \n",
    "\n",
    "For each selected ETF, we compute a variable named **Up** that is 1 if the price of the ETF went up the previous day, zero if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'SPYUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'SPYUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3           ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 6444     ┆ 2012-10-26 16:36:45.027933+00:… ┆ null               ┆ 2000-01-05 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 6444.0   ┆ 190.82591842184576              ┆ 144.02936415534128 ┆ 50.113057480959675        ┆ 645.989990234375          │\n",
      "│ High      ┆ 6444.0   ┆ 191.92668889779023              ┆ 144.7563930674051  ┆ 51.62493276253082         ┆ 646.1900024414062         │\n",
      "│ Low       ┆ 6444.0   ┆ 189.6269088728895               ┆ 143.23284984431902 ┆ 49.48618592302649         ┆ 642.6799926757812         │\n",
      "│ Close     ┆ 6444.0   ┆ 190.84933958343657              ┆ 144.06736661670922 ┆ 50.23106002807617         ┆ 644.9500122070312         │\n",
      "│ Volume    ┆ 6444.0   ┆ 105232386.51458721              ┆ 90179712.63917024  ┆ 1436600.0                 ┆ 871026300.0               │\n",
      "│ CloseLag1 ┆ 6444.0   ┆ 190.76379166087477              ┆ 143.96436701907055 ┆ 50.23106002807617         ┆ 644.9500122070312         │\n",
      "│ CloseLag2 ┆ 6444.0   ┆ 190.67826132712196              ┆ 143.85915506172498 ┆ 50.23106002807617         ┆ 644.9500122070312         │\n",
      "│ SPYUp     ┆ 6444.0   ┆ 0.5446927374301676              ┆ 0.4980371984141425 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌───────────────┬───────────┬───────────┬───────────┬───┬──────────┬───────────┬───────────┬───────┐\n",
      "│ Date          ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume   ┆ CloseLag1 ┆ CloseLag2 ┆ SPYUp │\n",
      "│ ---           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---      ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs,  ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64      ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]          ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "╞═══════════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2000-01-05    ┆ 88.657974 ┆ 89.6677   ┆ 86.955297 ┆ … ┆ 12177900 ┆ 88.539185 ┆ 92.142517 ┆ 0     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2000-01-06    ┆ 88.459986 ┆ 89.6479   ┆ 87.272072 ┆ … ┆ 6227200  ┆ 88.697571 ┆ 88.539185 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2000-01-07    ┆ 88.895594 ┆ 92.340546 ┆ 88.737205 ┆ … ┆ 8066500  ┆ 87.272072 ┆ 88.697571 ┆ 0     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2000-01-10    ┆ 92.657303 ┆ 93.073073 ┆ 91.885159 ┆ … ┆ 5741700  ┆ 92.340546 ┆ 87.272072 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2000-01-11    ┆ 92.380116 ┆ 92.558303 ┆ 90.915022 ┆ … ┆ 7503700  ┆ 92.657303 ┆ 92.340546 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "└───────────────┴───────────┴───────────┴───────────┴───┴──────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with SPY data\n",
    "spy = pl.read_csv(\"spy_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "spy = spy.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "spy = spy.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "spy = spy.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "spy = spy.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('SPYUp'))\n",
    "# check the schema\n",
    "print(spy.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "spy = spy.drop_nulls()\n",
    "\n",
    "spyStatistics = spy.describe()\n",
    "print(spyStatistics.columns)\n",
    "spyStatisticsToPrint = spyStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(spyStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(spy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'GLDUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'GLDUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬─────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3            ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪═════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                 ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 5218     ┆ 2015-04-04 10:38:49.858183+00:… ┆ null                ┆ 2004-11-22 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 5218.0   ┆ 132.1412112242237               ┆ 51.52670299042503   ┆ 41.029998779296875        ┆ 317.489990234375          │\n",
      "│ High      ┆ 5218.0   ┆ 132.77317369738134              ┆ 51.70272920655233   ┆ 41.36000061035156         ┆ 317.6300048828125         │\n",
      "│ Low       ┆ 5218.0   ┆ 131.45804141663464              ┆ 51.31802554569786   ┆ 41.02000045776367         ┆ 315.0400085449219         │\n",
      "│ Close     ┆ 5218.0   ┆ 132.14241081638417              ┆ 51.533912524483476  ┆ 41.2599983215332          ┆ 316.2900085449219         │\n",
      "│ Volume    ┆ 5218.0   ┆ 9420078.114220008               ┆ 6644238.186068209   ┆ 319300.0                  ┆ 93804200.0                │\n",
      "│ CloseLag1 ┆ 5218.0   ┆ 132.09248939242204              ┆ 51.49232280202278   ┆ 41.2599983215332          ┆ 316.2900085449219         │\n",
      "│ CloseLag2 ┆ 5218.0   ┆ 132.0421693442927               ┆ 51.44969185599339   ┆ 41.2599983215332          ┆ 316.2900085449219         │\n",
      "│ GLDUp     ┆ 5218.0   ┆ 0.5298965120735915              ┆ 0.49915323048311416 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴─────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌───────────────┬───────────┬───────────┬───────────┬───┬──────────┬───────────┬───────────┬───────┐\n",
      "│ Date          ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume   ┆ CloseLag1 ┆ CloseLag2 ┆ GLDUp │\n",
      "│ ---           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---      ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs,  ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64      ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]          ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "╞═══════════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2004-11-22    ┆ 44.75     ┆ 44.970001 ┆ 44.740002 ┆ … ┆ 11996000 ┆ 44.779999 ┆ 44.380001 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2004-11-23    ┆ 44.880001 ┆ 44.919998 ┆ 44.720001 ┆ … ┆ 3169200  ┆ 44.950001 ┆ 44.779999 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2004-11-24    ┆ 44.93     ┆ 45.049999 ┆ 44.790001 ┆ … ┆ 6105100  ┆ 44.75     ┆ 44.950001 ┆ 0     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2004-11-26    ┆ 45.25     ┆ 45.599998 ┆ 45.060001 ┆ … ┆ 3097700  ┆ 45.049999 ┆ 44.75     ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2004-11-29    ┆ 45.099998 ┆ 45.5      ┆ 45.080002 ┆ … ┆ 3759000  ┆ 45.290001 ┆ 45.049999 ┆ 1     │\n",
      "│ 05:00:00 UTC  ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆       │\n",
      "└───────────────┴───────────┴───────────┴───────────┴───┴──────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with GLD data\n",
    "gld = pl.read_csv(\"gld_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "gld = gld.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "gld = gld.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "gld = gld.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "gld = gld.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('GLDUp'))\n",
    "# check the schema\n",
    "print(gld.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "gld = gld.drop_nulls()\n",
    "\n",
    "gldStatistics = gld.describe()\n",
    "print(gldStatistics.columns)\n",
    "gldStatisticsToPrint = gldStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(gldStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(gld.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'VGTUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'VGTUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3           ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 5421     ┆ 2014-11-08 04:40:16.602103+00:… ┆ null               ┆ 2004-02-03 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 5421.0   ┆ 167.88651112658872              ┆ 165.87005650920398 ┆ 25.400250326119036        ┆ 710.0499877929688         │\n",
      "│ High      ┆ 5421.0   ┆ 169.15025730560342              ┆ 167.19942905975995 ┆ 26.273459632207647        ┆ 710.8800048828125         │\n",
      "│ Low       ┆ 5421.0   ┆ 166.46979142040922              ┆ 164.35842233160986 ┆ 24.68993342530967         ┆ 704.0                     │\n",
      "│ Close     ┆ 5421.0   ┆ 167.9006570834688               ┆ 165.88368753316217 ┆ 25.04936981201172         ┆ 707.2899780273438         │\n",
      "│ Volume    ┆ 5421.0   ┆ 360279.91145545105              ┆ 400808.0053902826  ┆ 0.0                       ┆ 6564500.0                 │\n",
      "│ CloseLag1 ┆ 5421.0   ┆ 167.78119283618796              ┆ 165.74161113685028 ┆ 25.04936981201172         ┆ 707.2899780273438         │\n",
      "│ CloseLag2 ┆ 5421.0   ┆ 167.65927450781356              ┆ 165.59152803560164 ┆ 25.04936981201172         ┆ 707.2899780273438         │\n",
      "│ VGTUp     ┆ 5421.0   ┆ 0.5543257701531082              ┆ 0.4970857990731627 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌──────────────┬───────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────┐\n",
      "│ Date         ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume ┆ CloseLag1 ┆ CloseLag2 ┆ VGTUp │\n",
      "│ ---          ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---    ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs, ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64    ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]         ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "╞══════════════╪═══════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2004-02-03   ┆ 40.925945 ┆ 40.942719 ┆ 40.774989 ┆ … ┆ 231100 ┆ 41.194313 ┆ 41.160759 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2004-02-04   ┆ 39.83571  ┆ 39.83571  ┆ 39.709911 ┆ … ┆ 51000  ┆ 40.942719 ┆ 41.194313 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2004-02-05   ┆ 40.003442 ┆ 40.003442 ┆ 39.709913 ┆ … ┆ 2600   ┆ 39.709911 ┆ 40.942719 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2004-02-06   ┆ 40.17116  ┆ 40.716278 ┆ 40.17116  ┆ … ┆ 1000   ┆ 39.91119  ┆ 39.709911 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2004-02-09   ┆ 40.791757 ┆ 40.917555 ┆ 40.607254 ┆ … ┆ 3200   ┆ 40.716278 ┆ 39.91119  ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "└──────────────┴───────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with VGT data\n",
    "vgt = pl.read_csv(\"vgt_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "vgt = vgt.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "vgt = vgt.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "vgt = vgt.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "vgt = vgt.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('VGTUp'))\n",
    "# check the schema\n",
    "print(vgt.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "vgt = vgt.drop_nulls()\n",
    "\n",
    "vgtStatistics = vgt.describe()\n",
    "print(vgtStatistics.columns)\n",
    "vgtStatisticsToPrint = vgtStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(vgtStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(vgt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'VBUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'VBUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬─────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3            ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪═════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                 ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 5421     ┆ 2014-11-08 04:40:16.602103+00:… ┆ null                ┆ 2004-02-03 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 5421.0   ┆ 106.9052813338388               ┆ 62.1452158206943    ┆ 23.633474085495507        ┆ 258.1815273395355         │\n",
      "│ High      ┆ 5421.0   ┆ 107.60790542830034              ┆ 62.54629697613006   ┆ 24.28031945289275         ┆ 260.4463040442688         │\n",
      "│ Low       ┆ 5421.0   ┆ 106.04389329572601              ┆ 61.67305864844019   ┆ 19.9520221629505          ┆ 257.5090323220884         │\n",
      "│ Close     ┆ 5421.0   ┆ 106.86636685982025              ┆ 62.11471701676378   ┆ 23.546703338623047        ┆ 258.69580078125           │\n",
      "│ Volume    ┆ 5421.0   ┆ 491339.45766463754              ┆ 522990.5325407978   ┆ 200.0                     ┆ 9288100.0                 │\n",
      "│ CloseLag1 ┆ 5421.0   ┆ 106.82761647115882              ┆ 62.09329247825284   ┆ 23.546703338623047        ┆ 258.69580078125           │\n",
      "│ CloseLag2 ┆ 5421.0   ┆ 106.78877441576543              ┆ 62.07172201176196   ┆ 23.546703338623047        ┆ 258.69580078125           │\n",
      "│ VBUp      ┆ 5421.0   ┆ 0.5366168603578676              ┆ 0.49870340245454003 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴─────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌──────────────┬───────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬──────┐\n",
      "│ Date         ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume ┆ CloseLag1 ┆ CloseLag2 ┆ VBUp │\n",
      "│ ---          ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---    ┆ ---       ┆ ---       ┆ ---  │\n",
      "│ datetime[μs, ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64    ┆ f64       ┆ f64       ┆ i32  │\n",
      "│ UTC]         ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "╞══════════════╪═══════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪══════╡\n",
      "│ 2004-02-03   ┆ 36.107417 ┆ 36.18088  ┆ 36.048645 ┆ … ┆ 1200   ┆ 36.14415  ┆ 35.997215 ┆ 1    │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "│ 2004-02-04   ┆ 35.872324 ┆ 35.872324 ┆ 35.299305 ┆ … ┆ 1600   ┆ 36.048645 ┆ 36.14415  ┆ 0    │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "│ 2004-02-05   ┆ 35.549099 ┆ 35.622565 ┆ 35.336054 ┆ … ┆ 4000   ┆ 35.299305 ┆ 36.048645 ┆ 0    │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "│ 2004-02-06   ┆ 35.615208 ┆ 36.254341 ┆ 35.615208 ┆ … ┆ 2000   ┆ 35.409519 ┆ 35.299305 ┆ 1    │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "│ 2004-02-09   ┆ 36.511441 ┆ 36.636328 ┆ 36.504093 ┆ … ┆ 2900   ┆ 36.254341 ┆ 35.409519 ┆ 1    │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆      │\n",
      "└──────────────┴───────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "# work with VB data\n",
    "vb = pl.read_csv(\"vb_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "vb = vb.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "vb = vb.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "vb = vb.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "vb = vb.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('VBUp'))\n",
    "# check the schema\n",
    "print(vb.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "vb = vb.drop_nulls()\n",
    "\n",
    "vbStatistics = vb.describe()\n",
    "print(vbStatistics.columns)\n",
    "vbStatisticsToPrint = vbStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(vbStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(vb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'IVEUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'IVEUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬─────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3            ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪═════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                 ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 6343     ┆ 2013-01-08 00:46:19.883336+00:… ┆ null                ┆ 2000-05-31 04:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 6343.0   ┆ 74.6655833423332                ┆ 46.11985052593699   ┆ 21.26051340242963         ┆ 203.21139722740784        │\n",
      "│ High      ┆ 6343.0   ┆ 75.06144188464853               ┆ 46.322477201398875  ┆ 22.014917670226524        ┆ 203.8427634546091         │\n",
      "│ Low       ┆ 6343.0   ┆ 74.22128225486621               ┆ 45.922028399013676  ┆ 20.797465831147417        ┆ 202.95489456330537        │\n",
      "│ Close     ┆ 6343.0   ┆ 74.66454975014508               ┆ 46.129873687318245  ┆ 21.3702449798584          ┆ 203.3889617919922         │\n",
      "│ Volume    ┆ 6343.0   ┆ 677624.5940406747               ┆ 792860.168455924    ┆ 400.0                     ┆ 20403600.0                │\n",
      "│ CloseLag1 ┆ 6343.0   ┆ 74.63817534400859               ┆ 46.10495666736668   ┆ 21.3702449798584          ┆ 203.3889617919922         │\n",
      "│ CloseLag2 ┆ 6343.0   ┆ 74.61178671650268               ┆ 46.080269741101944  ┆ 21.3702449798584          ┆ 203.3889617919922         │\n",
      "│ IVEUp     ┆ 6343.0   ┆ 0.5344474223553524              ┆ 0.49885128818986785 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴─────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌──────────────┬───────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────┐\n",
      "│ Date         ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume ┆ CloseLag1 ┆ CloseLag2 ┆ IVEUp │\n",
      "│ ---          ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---    ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs, ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64    ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]         ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "╞══════════════╪═══════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2000-05-31   ┆ 34.549207 ┆ 34.899005 ┆ 34.549207 ┆ … ┆ 12200  ┆ 34.567142 ┆ 34.046928 ┆ 1     │\n",
      "│ 04:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-06-01   ┆ 34.890046 ┆ 35.257782 ┆ 34.836231 ┆ … ┆ 25400  ┆ 34.827251 ┆ 34.567142 ┆ 1     │\n",
      "│ 04:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-06-02   ┆ 35.858717 ┆ 35.93047  ┆ 35.751087 ┆ … ┆ 10000  ┆ 35.257782 ┆ 34.827251 ┆ 1     │\n",
      "│ 04:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-06-05   ┆ 35.786959 ┆ 35.786959 ┆ 35.544792 ┆ … ┆ 15500  ┆ 35.751087 ┆ 35.257782 ┆ 1     │\n",
      "│ 04:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-06-06   ┆ 35.508916 ┆ 35.544792 ┆ 35.508916 ┆ … ┆ 4100   ┆ 35.589638 ┆ 35.751087 ┆ 0     │\n",
      "│ 04:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "└──────────────┴───────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with IVE data\n",
    "ive = pl.read_csv(\"ive_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "ive = ive.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "ive = ive.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "ive = ive.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "ive = ive.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('IVEUp'))\n",
    "# check the schema\n",
    "print(ive.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "ive = ive.drop_nulls()\n",
    "\n",
    "iveStatistics = ive.describe()\n",
    "print(iveStatistics.columns)\n",
    "iveStatisticsToPrint = iveStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(iveStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(ive.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'XLIUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'XLIUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3           ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 6444     ┆ 2012-10-26 16:36:45.027933+00:… ┆ null               ┆ 2000-01-05 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 6444.0   ┆ 47.13428678572114               ┆ 33.75933048208735  ┆ 11.236274653018539        ┆ 155.07000732421875        │\n",
      "│ High      ┆ 6444.0   ┆ 47.445254711260986              ┆ 33.95744459372276  ┆ 11.497583816634966        ┆ 155.14999389648438        │\n",
      "│ Low       ┆ 6444.0   ┆ 46.80200222742193               ┆ 33.55937913538952  ┆ 10.989484954974614        ┆ 154.07000732421875        │\n",
      "│ Close     ┆ 6444.0   ┆ 47.13715054336207               ┆ 33.76749713408024  ┆ 11.149171829223633        ┆ 154.99000549316406        │\n",
      "│ Volume    ┆ 6444.0   ┆ 8557567.116697703               ┆ 7392044.013283453  ┆ 400.0                     ┆ 79118200.0                │\n",
      "│ CloseLag1 ┆ 6444.0   ┆ 47.1164178205972                ┆ 33.74450283125619  ┆ 11.149171829223633        ┆ 154.99000549316406        │\n",
      "│ CloseLag2 ┆ 6444.0   ┆ 47.09581460485097               ┆ 33.72157067152891  ┆ 11.149171829223633        ┆ 154.99000549316406        │\n",
      "│ XLIUp     ┆ 6444.0   ┆ 0.5332091868404718              ┆ 0.4989346455594378 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌──────────────┬───────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────┐\n",
      "│ Date         ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume ┆ CloseLag1 ┆ CloseLag2 ┆ XLIUp │\n",
      "│ ---          ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---    ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs, ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64    ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]         ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "╞══════════════╪═══════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2000-01-05   ┆ 17.728652 ┆ 17.807798 ┆ 17.550574 ┆ … ┆ 129200 ┆ 17.758335 ┆ 18.262877 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-06   ┆ 17.679196 ┆ 17.9661   ┆ 17.609944 ┆ … ┆ 54000  ┆ 17.679186 ┆ 17.758335 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-07   ┆ 18.124382 ┆ 18.599257 ┆ 18.124382 ┆ … ┆ 32900  ┆ 17.916634 ┆ 17.679186 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-10   ┆ 18.698189 ┆ 18.757548 ┆ 18.539897 ┆ … ┆ 122500 ┆ 18.599257 ┆ 17.916634 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-11   ┆ 18.658613 ┆ 18.658613 ┆ 18.361816 ┆ … ┆ 109800 ┆ 18.599257 ┆ 18.599257 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "└──────────────┴───────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with XLI data\n",
    "xli = pl.read_csv(\"xli_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "xli = xli.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "xli = xli.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "xli = xli.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "xli = xli.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('XLIUp'))\n",
    "# check the schema\n",
    "print(xli.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "xli = xli.drop_nulls()\n",
    "\n",
    "xliStatistics = xli.describe()\n",
    "print(xliStatistics.columns)\n",
    "xliStatisticsToPrint = xliStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(xliStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(xli.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'XLUUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'XLUUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬─────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3            ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪═════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                 ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 6444     ┆ 2012-10-26 16:36:45.027933+00:… ┆ null                ┆ 2000-01-05 05:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 6444.0   ┆ 31.894989147350113              ┆ 19.721009673760992  ┆ 6.889745684259615         ┆ 87.3499984741211          │\n",
      "│ High      ┆ 6444.0   ┆ 32.123881544096875              ┆ 19.861535759212497  ┆ 7.41416278528114          ┆ 87.66999816894531         │\n",
      "│ Low       ┆ 6444.0   ┆ 31.650661453103062              ┆ 19.573122239135174  ┆ 6.736037375918337         ┆ 86.12999725341797         │\n",
      "│ Close     ┆ 6444.0   ┆ 31.89608001967974               ┆ 19.7271434580805    ┆ 6.885226726531982         ┆ 87.31999969482422         │\n",
      "│ Volume    ┆ 6444.0   ┆ 8837735.055865921               ┆ 7372839.575100792   ┆ 3200.0                    ┆ 90263100.0                │\n",
      "│ CloseLag1 ┆ 6444.0   ┆ 31.88441676186302               ┆ 19.717318739292757  ┆ 6.885226726531982         ┆ 87.31999969482422         │\n",
      "│ CloseLag2 ┆ 6444.0   ┆ 31.8729350237577                ┆ 19.707778243189146  ┆ 6.885226726531982         ┆ 87.31999969482422         │\n",
      "│ XLUUp     ┆ 6444.0   ┆ 0.5335195530726257              ┆ 0.49891388733682634 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴─────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌──────────────┬───────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────┐\n",
      "│ Date         ┆ Open      ┆ High      ┆ Low       ┆ … ┆ Volume ┆ CloseLag1 ┆ CloseLag2 ┆ XLUUp │\n",
      "│ ---          ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---    ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs, ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i64    ┆ f64       ┆ f64       ┆ i32   │\n",
      "│ UTC]         ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "╞══════════════╪═══════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2000-01-05   ┆ 11.165537 ┆ 11.248862 ┆ 11.018116 ┆ … ┆ 273400 ┆ 10.921968 ┆ 11.26168  ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-06   ┆ 11.178358 ┆ 11.178358 ┆ 11.050166 ┆ … ┆ 34500  ┆ 11.197585 ┆ 10.921968 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-07   ┆ 11.197586 ┆ 11.274501 ┆ 11.146309 ┆ … ┆ 46200  ┆ 11.178358 ┆ 11.197585 ┆ 0     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-10   ┆ 11.268088 ┆ 11.345003 ┆ 11.248859 ┆ … ┆ 15500  ┆ 11.274501 ┆ 11.178358 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "│ 2000-01-11   ┆ 11.261679 ┆ 11.261679 ┆ 11.107849 ┆ … ┆ 25700  ┆ 11.312955 ┆ 11.274501 ┆ 1     │\n",
      "│ 05:00:00 UTC ┆           ┆           ┆           ┆   ┆        ┆           ┆           ┆       │\n",
      "└──────────────┴───────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with XLU data\n",
    "xlu = pl.read_csv(\"xlu_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "xlu = xlu.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "xlu = xlu.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "xlu = xlu.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "xlu = xlu.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('XLUUp'))\n",
    "# check the schema\n",
    "print(xlu.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "xlu = xlu.drop_nulls()\n",
    "\n",
    "xluStatistics = xlu.describe()\n",
    "print(xluStatistics.columns)\n",
    "xluStatisticsToPrint = xluStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(xluStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(xlu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'SLVUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'SLVUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3           ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 4856     ┆ 2015-12-23 02:12:58.418451+00:… ┆ null               ┆ 2006-05-02 04:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 4856.0   ┆ 19.84649361829585               ┆ 6.487981729697927  ┆ 8.710000038146973         ┆ 47.619998931884766        │\n",
      "│ High      ┆ 4856.0   ┆ 20.0214888811897                ┆ 6.55865103290389   ┆ 9.050000190734863         ┆ 48.349998474121094        │\n",
      "│ Low       ┆ 4856.0   ┆ 19.649800242859214              ┆ 6.395723154542012  ┆ 8.449999809265137         ┆ 46.54999923706055         │\n",
      "│ Close     ┆ 4856.0   ┆ 19.840868817129873              ┆ 6.487317455039558  ┆ 8.850000381469727         ┆ 47.2599983215332          │\n",
      "│ Volume    ┆ 4856.0   ┆ 15420806.878088962              ┆ 16683460.219457056 ┆ 1039000.0                 ┆ 295400000.0               │\n",
      "│ CloseLag1 ┆ 4856.0   ┆ 19.83675020118129               ┆ 6.484757133225693  ┆ 8.850000381469727         ┆ 47.2599983215332          │\n",
      "│ CloseLag2 ┆ 4856.0   ┆ 19.832479608314237              ┆ 6.481893562087745  ┆ 8.850000381469727         ┆ 47.2599983215332          │\n",
      "│ SLVUp     ┆ 4856.0   ┆ 0.5168863261943987              ┆ 0.4997662319131529 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌─────────────────────┬────────┬────────┬────────┬───┬──────────┬───────────┬───────────┬───────┐\n",
      "│ Date                ┆ Open   ┆ High   ┆ Low    ┆ … ┆ Volume   ┆ CloseLag1 ┆ CloseLag2 ┆ SLVUp │\n",
      "│ ---                 ┆ ---    ┆ ---    ┆ ---    ┆   ┆ ---      ┆ ---       ┆ ---       ┆ ---   │\n",
      "│ datetime[μs, UTC]   ┆ f64    ┆ f64    ┆ f64    ┆   ┆ i64      ┆ f64       ┆ f64       ┆ i32   │\n",
      "╞═════════════════════╪════════╪════════╪════════╪═══╪══════════╪═══════════╪═══════════╪═══════╡\n",
      "│ 2006-05-02 04:00:00 ┆ 14.245 ┆ 14.4   ┆ 14.1   ┆ … ┆ 12511000 ┆ 13.87     ┆ 13.812    ┆ 1     │\n",
      "│ UTC                 ┆        ┆        ┆        ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2006-05-03 04:00:00 ┆ 14.45  ┆ 14.464 ┆ 13.413 ┆ … ┆ 15141000 ┆ 14.365    ┆ 13.87     ┆ 1     │\n",
      "│ UTC                 ┆        ┆        ┆        ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2006-05-04 04:00:00 ┆ 13.95  ┆ 14.287 ┆ 13.68  ┆ … ┆ 11075000 ┆ 13.925    ┆ 14.365    ┆ 0     │\n",
      "│ UTC                 ┆        ┆        ┆        ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2006-05-05 04:00:00 ┆ 14.0   ┆ 14.03  ┆ 13.75  ┆ … ┆ 6586000  ┆ 14.0      ┆ 13.925    ┆ 1     │\n",
      "│ UTC                 ┆        ┆        ┆        ┆   ┆          ┆           ┆           ┆       │\n",
      "│ 2006-05-08 04:00:00 ┆ 13.8   ┆ 14.0   ┆ 13.506 ┆ … ┆ 9453000  ┆ 13.995    ┆ 14.0      ┆ 0     │\n",
      "│ UTC                 ┆        ┆        ┆        ┆   ┆          ┆           ┆           ┆       │\n",
      "└─────────────────────┴────────┴────────┴────────┴───┴──────────┴───────────┴───────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with SLV data\n",
    "slv = pl.read_csv(\"slv_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "slv = slv.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "slv = slv.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "slv = slv.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "slv = slv.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('SLVUp'))\n",
    "# check the schema\n",
    "print(slv.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "slv = slv.drop_nulls()\n",
    "\n",
    "slvStatistics = slv.describe()\n",
    "print(slvStatistics.columns)\n",
    "slvStatisticsToPrint = slvStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(slvStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(slv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'Open': Float64, 'High': Float64, 'Low': Float64, 'Close': Float64, 'Volume': Int64, 'CloseLag1': Float64, 'CloseLag2': Float64, 'USOUp': Int32})\n",
      "['statistic', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'CloseLag1', 'CloseLag2', 'USOUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_6': String, 'column_8': String})\n",
      "┌───────────┬──────────┬─────────────────────────────────┬─────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ column    ┆ column_0 ┆ column_2                        ┆ column_3            ┆ column_4                  ┆ column_8                  │\n",
      "╞═══════════╪══════════╪═════════════════════════════════╪═════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ statistic ┆ count    ┆ mean                            ┆ std                 ┆ min                       ┆ max                       │\n",
      "│ Date      ┆ 4869     ┆ 2015-12-13 15:52:11.238447+00:… ┆ null                ┆ 2006-04-12 04:00:00+00:00 ┆ 2025-08-19 04:00:00+00:00 │\n",
      "│ Open      ┆ 4869.0   ┆ 207.56218537914114              ┆ 172.12513325570848  ┆ 17.280000686645508        ┆ 952.6400146484375         │\n",
      "│ High      ┆ 4869.0   ┆ 209.87204556632614              ┆ 174.16241714493188  ┆ 18.0                      ┆ 953.3599853515625         │\n",
      "│ Low       ┆ 4869.0   ┆ 205.02635254098982              ┆ 169.7785603051359   ┆ 16.8799991607666          ┆ 932.0                     │\n",
      "│ Close     ┆ 4869.0   ┆ 207.54419582231404              ┆ 172.08918039384076  ┆ 17.040000915527344        ┆ 939.8400268554688         │\n",
      "│ Volume    ┆ 4869.0   ┆ 3012812.4988704044              ┆ 4036484.7365261046  ┆ 14888.0                   ┆ 124913013.0               │\n",
      "│ CloseLag1 ┆ 4869.0   ┆ 207.64140263532167              ┆ 172.14643555816238  ┆ 17.040000915527344        ┆ 939.8400268554688         │\n",
      "│ CloseLag2 ┆ 4869.0   ┆ 207.73813501876296              ┆ 172.20317777305166  ┆ 17.040000915527344        ┆ 939.8400268554688         │\n",
      "│ USOUp     ┆ 4869.0   ┆ 0.5103717395769152              ┆ 0.49994375754988574 ┆ 0.0                       ┆ 1.0                       │\n",
      "└───────────┴──────────┴─────────────────────────────────┴─────────────────────┴───────────────────────────┴───────────────────────────┘\n",
      "shape: (5, 9)\n",
      "┌────────────┬────────────┬────────────┬────────────┬───┬────────┬────────────┬────────────┬───────┐\n",
      "│ Date       ┆ Open       ┆ High       ┆ Low        ┆ … ┆ Volume ┆ CloseLag1  ┆ CloseLag2  ┆ USOUp │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆   ┆ ---    ┆ ---        ┆ ---        ┆ ---   │\n",
      "│ datetime[μ ┆ f64        ┆ f64        ┆ f64        ┆   ┆ i64    ┆ f64        ┆ f64        ┆ i32   │\n",
      "│ s, UTC]    ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "╞════════════╪════════════╪════════════╪════════════╪═══╪════════╪════════════╪════════════╪═══════╡\n",
      "│ 2006-04-12 ┆ 545.76001  ┆ 550.47998  ┆ 542.47998  ┆ … ┆ 156038 ┆ 545.599976 ┆ 544.159973 ┆ 1     │\n",
      "│ 04:00:00   ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ UTC        ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ 2006-04-13 ┆ 540.0      ┆ 551.919983 ┆ 539.200012 ┆ … ┆ 70088  ┆ 542.719971 ┆ 545.599976 ┆ 0     │\n",
      "│ 04:00:00   ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ UTC        ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ 2006-04-17 ┆ 553.599976 ┆ 559.200012 ┆ 549.440002 ┆ … ┆ 114713 ┆ 550.559998 ┆ 542.719971 ┆ 1     │\n",
      "│ 04:00:00   ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ UTC        ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ 2006-04-18 ┆ 560.799988 ┆ 568.400024 ┆ 556.559998 ┆ … ┆ 115338 ┆ 558.320007 ┆ 550.559998 ┆ 1     │\n",
      "│ 04:00:00   ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ UTC        ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ 2006-04-19 ┆ 564.640015 ┆ 577.280029 ┆ 563.919983 ┆ … ┆ 98725  ┆ 566.0      ┆ 558.320007 ┆ 1     │\n",
      "│ 04:00:00   ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "│ UTC        ┆            ┆            ┆            ┆   ┆        ┆            ┆            ┆       │\n",
      "└────────────┴────────────┴────────────┴────────────┴───┴────────┴────────────┴────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# work with USO data\n",
    "uso = pl.read_csv(\"uso_daily_data.csv\", try_parse_dates=True)\n",
    "\n",
    "# drop useless columns Dividends, StockSplits, and CapitalGains\n",
    "uso = uso.drop(['Dividends', 'StockSplits', 'CapitalGains'])\n",
    "\n",
    "uso = uso.with_columns((pl.col('Close')).shift().alias('CloseLag1'))\n",
    "uso = uso.with_columns((pl.col('CloseLag1')).shift().alias('CloseLag2'))\n",
    "uso = uso.with_columns(pl.when(pl.col('CloseLag1')>pl.col('CloseLag2')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('USOUp'))\n",
    "# check the schema\n",
    "print(uso.schema)\n",
    "                       \n",
    "# Drop initial lag row\n",
    "uso = uso.drop_nulls()\n",
    "\n",
    "usoStatistics = uso.describe()\n",
    "print(usoStatistics.columns)\n",
    "usoStatisticsToPrint = usoStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(wtiStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(usoStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(uso.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum Date on which to select, minDateAll: 2006-05-02 04:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Find earliest date that can be used across all DataFrames\n",
    "minDateAll = max(min(wti['Date']),min(spy['Date']),min(gld['Date']),\n",
    "                 min(vgt['Date']),min(vb['Date']),min(ive['Date']),\n",
    "                 min(xli['Date']),min(xlu['Date']),min(slv['Date']),min(uso['Date']))    \n",
    "\n",
    "print(\"minimum Date on which to select, minDateAll:\", minDateAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum Date on which to select, axDateAll: 2025-08-19 04:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# find latest date across all DataFrames\n",
    "\n",
    "maxDateAll = min(max(wti['Date']),max(spy['Date']),max(gld['Date']),\n",
    "                 max(vgt['Date']),max(vb['Date']),max(ive['Date']),\n",
    "                 max(xli['Date']),max(xlu['Date']),max(slv['Date']),max(uso['Date']))    \n",
    "\n",
    "print(\"maximum Date on which to select, axDateAll:\", maxDateAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning of wti training set\n",
      "shape: (5, 17)\n",
      "┌─────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
      "│ Date        ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA8 ┆ Target │\n",
      "│ ---         ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---    │\n",
      "│ datetime[μs ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32    │\n",
      "│ , UTC]      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "╞═════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│ 2006-05-02  ┆ 32.19     ┆ 31.062    ┆ 30.669    ┆ … ┆ 31.649    ┆ 31.684    ┆ 31.697    ┆ 1      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2006-05-03  ┆ 33.471    ┆ 32.19     ┆ 31.062    ┆ … ┆ 32.56     ┆ 32.208    ┆ 31.979    ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2006-05-04  ┆ 33.158    ┆ 33.471    ┆ 32.19     ┆ … ┆ 32.859    ┆ 32.486    ┆ 32.167    ┆ 1      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2006-05-05  ┆ 35.013    ┆ 33.158    ┆ 33.471    ┆ … ┆ 33.936    ┆ 33.226    ┆ 32.62     ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2006-05-08  ┆ 33.645    ┆ 35.013    ┆ 33.158    ┆ … ┆ 33.791    ┆ 33.349    ┆ 32.783    ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "└─────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘\n",
      "End of wti training set\n",
      "shape: (5, 17)\n",
      "┌─────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
      "│ Date        ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA8 ┆ Target │\n",
      "│ ---         ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---    │\n",
      "│ datetime[μs ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32    │\n",
      "│ , UTC]      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "╞═════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│ 2024-12-23  ┆ 1.413     ┆ 1.344     ┆ 1.442     ┆ … ┆ 1.42      ┆ 1.483     ┆ 1.585     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2024-12-24  ┆ 1.481     ┆ 1.413     ┆ 1.344     ┆ … ┆ 1.451     ┆ 1.482     ┆ 1.569     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2024-12-26  ┆ 1.501     ┆ 1.481     ┆ 1.413     ┆ … ┆ 1.476     ┆ 1.488     ┆ 1.558     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2024-12-27  ┆ 1.54      ┆ 1.501     ┆ 1.481     ┆ … ┆ 1.508     ┆ 1.503     ┆ 1.555     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2024-12-30  ┆ 1.579     ┆ 1.54      ┆ 1.501     ┆ … ┆ 1.544     ┆ 1.525     ┆ 1.559     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "└─────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘\n",
      "Beginning of wti test set\n",
      "shape: (5, 17)\n",
      "┌─────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
      "│ Date        ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA8 ┆ Target │\n",
      "│ ---         ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---    │\n",
      "│ datetime[μs ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32    │\n",
      "│ , UTC]      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "╞═════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│ 2025-01-02  ┆ 1.628     ┆ 1.638     ┆ 1.579     ┆ … ┆ 1.61      ┆ 1.579     ┆ 1.581     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-01-03  ┆ 1.746     ┆ 1.628     ┆ 1.638     ┆ … ┆ 1.678     ┆ 1.628     ┆ 1.607     ┆ 0      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-01-06  ┆ 1.727     ┆ 1.746     ┆ 1.628     ┆ … ┆ 1.702     ┆ 1.657     ┆ 1.626     ┆ 0      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-01-07  ┆ 1.619     ┆ 1.727     ┆ 1.746     ┆ … ┆ 1.66      ┆ 1.646     ┆ 1.625     ┆ 0      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-01-08  ┆ 1.599     ┆ 1.619     ┆ 1.727     ┆ … ┆ 1.63      ┆ 1.632     ┆ 1.621     ┆ 1      │\n",
      "│ 05:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "└─────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘\n",
      "End of wti test set\n",
      "shape: (5, 17)\n",
      "┌─────────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬────────┐\n",
      "│ Date        ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA8 ┆ Target │\n",
      "│ ---         ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---    │\n",
      "│ datetime[μs ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ i32    │\n",
      "│ , UTC]      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "╞═════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪════════╡\n",
      "│ 2025-08-13  ┆ 1.74      ┆ 1.71      ┆ 1.72      ┆ … ┆ 1.729     ┆ 1.731     ┆ 1.737     ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-08-14  ┆ 1.74      ┆ 1.74      ┆ 1.71      ┆ … ┆ 1.734     ┆ 1.733     ┆ 1.737     ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-08-15  ┆ 1.74      ┆ 1.74      ┆ 1.74      ┆ … ┆ 1.737     ┆ 1.735     ┆ 1.737     ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-08-18  ┆ 1.71      ┆ 1.74      ┆ 1.74      ┆ … ┆ 1.724     ┆ 1.728     ┆ 1.733     ┆ 1      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ 2025-08-19  ┆ 1.74      ┆ 1.71      ┆ 1.74      ┆ … ┆ 1.732     ┆ 1.731     ┆ 1.734     ┆ 0      │\n",
      "│ 04:00:00    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "│ UTC         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆        │\n",
      "└─────────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# select training data from minDateAll to 2024-12-31, test data all dates in 2025\n",
    "beginTrain = minDateAll\n",
    "endTrain = datetime(2024, 12, 31, tzinfo=timezone.utc)\n",
    "beginTest = datetime(2025, 1, 1, tzinfo=timezone.utc)\n",
    "endTest = maxDateAll\n",
    "wtiTrain = wti.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "wtiTest = wti.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "print(\"Beginning of wti training set\")\n",
    "print(wtiTrain.head())\n",
    "print(\"End of wti training set\")\n",
    "print(wtiTrain.tail())\n",
    "print(\"Beginning of wti test set\")\n",
    "print(wtiTest.head())\n",
    "print(\"End of wti test set\")\n",
    "print(wtiTest.tail())\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the WTI Target for Training and Test Sets\n",
    "Using the dates defined by looking across all ETFs and the WTI time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "┌────────┬───────┐\n",
      "│ Target ┆ count │\n",
      "│ ---    ┆ ---   │\n",
      "│ i32    ┆ u32   │\n",
      "╞════════╪═══════╡\n",
      "│ 1      ┆ 2227  │\n",
      "│ 0      ┆ 2471  │\n",
      "└────────┴───────┘\n",
      "shape: (2, 2)\n",
      "┌────────┬───────┐\n",
      "│ Target ┆ count │\n",
      "│ ---    ┆ ---   │\n",
      "│ i32    ┆ u32   │\n",
      "╞════════╪═══════╡\n",
      "│ 1      ┆ 72    │\n",
      "│ 0      ┆ 85    │\n",
      "└────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Define and examine the target for classification model development\n",
    "print(wtiTrain['Target'].value_counts())\n",
    "yTrain = np.array(wtiTrain['Target'])\n",
    "\n",
    "print(wtiTest['Target'].value_counts())\n",
    "yTest = np.array(wtiTest['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Target from WTI Data Sets\n",
    "The initial feature set will include price features from WTI. Having obtained the Target from both the training and test data for WTI, we remove it from the WTI feature set in both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>CloseLag1</th><th>CloseLag2</th><th>CloseLag3</th><th>HMLLag1</th><th>HMLLag2</th><th>HMLLag3</th><th>OMCLag1</th><th>OMCLag2</th><th>OMCLag3</th><th>VolumeLag1</th><th>VolumeLag2</th><th>VolumeLag3</th><th>CloseEMA2</th><th>CloseEMA4</th><th>CloseEMA8</th></tr><tr><td>datetime[μs, UTC]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2025-01-02 05:00:00 UTC</td><td>1.628</td><td>1.638</td><td>1.579</td><td>0.059</td><td>0.108</td><td>0.098</td><td>0.0</td><td>-0.029</td><td>-0.01</td><td>2.2437e6</td><td>3.6429e6</td><td>2.5184e6</td><td>1.61</td><td>1.579</td><td>1.581</td></tr><tr><td>2025-01-03 05:00:00 UTC</td><td>1.746</td><td>1.628</td><td>1.638</td><td>0.128</td><td>0.059</td><td>0.108</td><td>-0.078</td><td>0.0</td><td>-0.029</td><td>3.4821e6</td><td>2.2437e6</td><td>3.6429e6</td><td>1.678</td><td>1.628</td><td>1.607</td></tr><tr><td>2025-01-06 05:00:00 UTC</td><td>1.727</td><td>1.746</td><td>1.628</td><td>0.088</td><td>0.128</td><td>0.059</td><td>0.039</td><td>-0.078</td><td>0.0</td><td>1.4409e6</td><td>3.4821e6</td><td>2.2437e6</td><td>1.702</td><td>1.657</td><td>1.626</td></tr><tr><td>2025-01-07 05:00:00 UTC</td><td>1.619</td><td>1.727</td><td>1.746</td><td>0.167</td><td>0.088</td><td>0.128</td><td>0.128</td><td>0.039</td><td>-0.078</td><td>2.5746e6</td><td>1.4409e6</td><td>3.4821e6</td><td>1.66</td><td>1.646</td><td>1.625</td></tr><tr><td>2025-01-08 05:00:00 UTC</td><td>1.599</td><td>1.619</td><td>1.727</td><td>0.098</td><td>0.167</td><td>0.088</td><td>0.029</td><td>0.128</td><td>0.039</td><td>2.2995e6</td><td>2.5746e6</td><td>1.4409e6</td><td>1.63</td><td>1.632</td><td>1.621</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ Date      ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ VolumeLag ┆ CloseEMA2 ┆ CloseEMA4 ┆ CloseEMA │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ 3         ┆ ---       ┆ ---       ┆ 8        │\n",
       "│ datetime[ ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ f64       ┆ f64       ┆ ---      │\n",
       "│ μs, UTC]  ┆           ┆           ┆           ┆   ┆ f64       ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 2025-01-0 ┆ 1.628     ┆ 1.638     ┆ 1.579     ┆ … ┆ 2.5184e6  ┆ 1.61      ┆ 1.579     ┆ 1.581    │\n",
       "│ 2         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 05:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ UTC       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2025-01-0 ┆ 1.746     ┆ 1.628     ┆ 1.638     ┆ … ┆ 3.6429e6  ┆ 1.678     ┆ 1.628     ┆ 1.607    │\n",
       "│ 3         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 05:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ UTC       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2025-01-0 ┆ 1.727     ┆ 1.746     ┆ 1.628     ┆ … ┆ 2.2437e6  ┆ 1.702     ┆ 1.657     ┆ 1.626    │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 05:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ UTC       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2025-01-0 ┆ 1.619     ┆ 1.727     ┆ 1.746     ┆ … ┆ 3.4821e6  ┆ 1.66      ┆ 1.646     ┆ 1.625    │\n",
       "│ 7         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 05:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ UTC       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2025-01-0 ┆ 1.599     ┆ 1.619     ┆ 1.727     ┆ … ┆ 1.4409e6  ┆ 1.63      ┆ 1.632     ┆ 1.621    │\n",
       "│ 8         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 05:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ UTC       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Having extracted the Target from the WTI training and test sets, we can delete it from the set of features\n",
    "XTrain = wtiTrain.drop(['Target'])\n",
    "XTrain.head()\n",
    "\n",
    "XTest = wtiTest.drop(['Target'])\n",
    "XTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by date for all the ETF DataFrames, defining training and test sets\n",
    "\n",
    "spyTrain = spy.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "spyTest = spy.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "gldTrain = gld.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "gldTest = gld.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "vgtTrain = vgt.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "vgtTest = vgt.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "vbTrain = vb.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "vbTest = vb.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "iveTrain = ive.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "iveTest = ive.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "xliTrain = xli.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "xliTest = xli.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "xluTrain = xlu.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "xluTest = xlu.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "slvTrain = slv.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "slvTest = slv.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n",
    "\n",
    "usoTrain = uso.filter((pl.col('Date')>=beginTrain) & (pl.col('Date')<=endTrain))\n",
    "usoTest = uso.filter((pl.col('Date')>=beginTest) & (pl.col('Date')<=endTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame shapes:\n",
      "wtiTrain.shape:  (4698, 17)\n",
      "spyTrain.shape:  (4698, 9)\n",
      "gldTrain.shape:  (4698, 9)\n",
      "vgtTrain.shape:  (4698, 9)\n",
      "vbTrain.shape:  (4698, 9)\n",
      "iveTrain.shape:  (4698, 9)\n",
      "xliTrain.shape:  (4698, 9)\n",
      "xluTrain.shape:  (4698, 9)\n",
      "slvTrain.shape:  (4698, 9)\n",
      "usoTrain.shape:  (4698, 9)\n",
      "Test DataFrame shapes:\n",
      "wtiTest.shape:  (157, 17)\n",
      "spyTest.shape:  (157, 9)\n",
      "gldTest.shape:  (157, 9)\n",
      "vgtTest.shape:  (157, 9)\n",
      "vbTest.shape:  (157, 9)\n",
      "iveTest.shape:  (157, 9)\n",
      "xliTest.shape:  (157, 9)\n",
      "xluTest.shape:  (157, 9)\n",
      "slvTest.shape:  (157, 9)\n",
      "usoTest.shape:  (157, 9)\n"
     ]
    }
   ],
   "source": [
    "# verify consistent shapes of DataFrames\n",
    "print(\"Train DataFrame shapes:\")\n",
    "print(\"wtiTrain.shape: \", wtiTrain.shape)\n",
    "print(\"spyTrain.shape: \", spyTrain.shape)\n",
    "print(\"gldTrain.shape: \", gldTrain.shape)\n",
    "print(\"vgtTrain.shape: \", vgtTrain.shape)\n",
    "print(\"vbTrain.shape: \", vbTrain.shape)\n",
    "print(\"iveTrain.shape: \", iveTrain.shape)\n",
    "print(\"xliTrain.shape: \", xliTrain.shape)\n",
    "print(\"xluTrain.shape: \", xluTrain.shape)\n",
    "print(\"slvTrain.shape: \", slvTrain.shape)\n",
    "print(\"usoTrain.shape: \", usoTrain.shape)\n",
    "# verify consistent shapes of DataFrames\n",
    "print(\"Test DataFrame shapes:\")\n",
    "print(\"wtiTest.shape: \", wtiTest.shape)\n",
    "print(\"spyTest.shape: \", spyTest.shape)\n",
    "print(\"gldTest.shape: \", gldTest.shape)\n",
    "print(\"vgtTest.shape: \", vgtTest.shape)\n",
    "print(\"vbTest.shape: \", vbTest.shape)\n",
    "print(\"iveTest.shape: \", iveTest.shape)\n",
    "print(\"xliTest.shape: \", xliTest.shape)\n",
    "print(\"xluTest.shape: \", xluTest.shape)\n",
    "print(\"slvTest.shape: \", slvTest.shape)\n",
    "print(\"usoTest.shape: \", usoTest.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'CloseLag1': Float64, 'CloseLag2': Float64, 'CloseLag3': Float64, 'HMLLag1': Float64, 'HMLLag2': Float64, 'HMLLag3': Float64, 'OMCLag1': Float64, 'OMCLag2': Float64, 'OMCLag3': Float64, 'VolumeLag1': Float64, 'VolumeLag2': Float64, 'VolumeLag3': Float64, 'CloseEMA2': Float64, 'CloseEMA4': Float64, 'CloseEMA8': Float64, 'Target': Int32, 'SPYUp': Int32, 'GLDUp': Int32, 'VGTUp': Int32, 'VBUp': Int32, 'IVEUp': Int32, 'XLIUp': Int32, 'XLUUp': Int32, 'SLVUp': Int32, 'USOUp': Int32})\n",
      "shape: (5, 26)\n",
      "┌─────────────────────────┬───────────┬───────────┬───────────┬───┬───────┬───────┬───────┬───────┐\n",
      "│ Date                    ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ XLIUp ┆ XLUUp ┆ SLVUp ┆ USOUp │\n",
      "│ ---                     ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
      "│ datetime[μs, UTC]       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i32   ┆ i32   ┆ i32   ┆ i32   │\n",
      "╞═════════════════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════╪═══════╪═══════╪═══════╡\n",
      "│ 2006-05-02 04:00:00 UTC ┆ 32.19     ┆ 31.062    ┆ 30.669    ┆ … ┆ 1     ┆ 0     ┆ 1     ┆ 1     │\n",
      "│ 2006-05-03 04:00:00 UTC ┆ 33.471    ┆ 32.19     ┆ 31.062    ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 2006-05-04 04:00:00 UTC ┆ 33.158    ┆ 33.471    ┆ 32.19     ┆ … ┆ 1     ┆ 0     ┆ 0     ┆ 0     │\n",
      "│ 2006-05-05 04:00:00 UTC ┆ 35.013    ┆ 33.158    ┆ 33.471    ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 0     │\n",
      "│ 2006-05-08 04:00:00 UTC ┆ 33.645    ┆ 35.013    ┆ 33.158    ┆ … ┆ 1     ┆ 1     ┆ 0     ┆ 0     │\n",
      "└─────────────────────────┴───────────┴───────────┴───────────┴───┴───────┴───────┴───────┴───────┘\n",
      "Schema({'Date': Datetime(time_unit='us', time_zone='UTC'), 'CloseLag1': Float64, 'CloseLag2': Float64, 'CloseLag3': Float64, 'HMLLag1': Float64, 'HMLLag2': Float64, 'HMLLag3': Float64, 'OMCLag1': Float64, 'OMCLag2': Float64, 'OMCLag3': Float64, 'VolumeLag1': Float64, 'VolumeLag2': Float64, 'VolumeLag3': Float64, 'CloseEMA2': Float64, 'CloseEMA4': Float64, 'CloseEMA8': Float64, 'Target': Int32, 'SPYUp': Int32, 'GLDUp': Int32, 'VGTUp': Int32, 'VBUp': Int32, 'IVEUp': Int32, 'XLIUp': Int32, 'XLUUp': Int32, 'SLVUp': Int32, 'USOUp': Int32})\n",
      "shape: (5, 26)\n",
      "┌─────────────────────────┬───────────┬───────────┬───────────┬───┬───────┬───────┬───────┬───────┐\n",
      "│ Date                    ┆ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ … ┆ XLIUp ┆ XLUUp ┆ SLVUp ┆ USOUp │\n",
      "│ ---                     ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
      "│ datetime[μs, UTC]       ┆ f64       ┆ f64       ┆ f64       ┆   ┆ i32   ┆ i32   ┆ i32   ┆ i32   │\n",
      "╞═════════════════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════╪═══════╪═══════╪═══════╡\n",
      "│ 2025-01-02 05:00:00 UTC ┆ 1.628     ┆ 1.638     ┆ 1.579     ┆ … ┆ 0     ┆ 0     ┆ 0     ┆ 1     │\n",
      "│ 2025-01-03 05:00:00 UTC ┆ 1.746     ┆ 1.628     ┆ 1.638     ┆ … ┆ 0     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 2025-01-06 05:00:00 UTC ┆ 1.727     ┆ 1.746     ┆ 1.628     ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 2025-01-07 05:00:00 UTC ┆ 1.619     ┆ 1.727     ┆ 1.746     ┆ … ┆ 0     ┆ 0     ┆ 1     ┆ 0     │\n",
      "│ 2025-01-08 05:00:00 UTC ┆ 1.599     ┆ 1.619     ┆ 1.727     ┆ … ┆ 0     ┆ 0     ┆ 1     ┆ 1     │\n",
      "└─────────────────────────┴───────────┴───────────┴───────────┴───┴───────┴───────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "# Add Up indicator variables to the wti DataFrames\n",
    "wtiTrainETF = wtiTrain\n",
    "wtiTrainETF = wtiTrainETF.with_columns(spyTrain['SPYUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(gldTrain['GLDUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(vgtTrain['VGTUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(vbTrain['VBUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(iveTrain['IVEUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(xliTrain['XLIUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(xluTrain['XLUUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(slvTrain['SLVUp'])\n",
    "wtiTrainETF = wtiTrainETF.with_columns(usoTrain['USOUp'])\n",
    "print(wtiTrainETF.schema)\n",
    "print(wtiTrainETF.head())\n",
    "\n",
    "wtiTestETF = wtiTest\n",
    "wtiTestETF = wtiTestETF.with_columns(spyTest['SPYUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(gldTest['GLDUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(vgtTest['VGTUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(vbTest['VBUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(iveTest['IVEUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(xliTest['XLIUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(xluTest['XLUUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(slvTest['SLVUp'])\n",
    "wtiTestETF = wtiTestETF.with_columns(usoTest['USOUp'])\n",
    "print(wtiTestETF.schema)\n",
    "print(wtiTestETF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now drop Date and Target from wti training and test sets\n",
    "# as we now have the full set o features for training and testing\n",
    "wtiTrainETF = wtiTrainETF.drop(['Date','Target'])\n",
    "wtiTestETF = wtiTestETF.drop(['Date','Target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CloseLag1', 'CloseLag2', 'CloseLag3', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'SPYUp', 'GLDUp', 'VGTUp', 'VBUp', 'IVEUp', 'XLIUp', 'XLUUp', 'SLVUp', 'USOUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_8': String})\n",
      "┌────────────┬──────────┬──────────────────────┬─────────────────────┬──────────┬────────────┐\n",
      "│ column     ┆ column_0 ┆ column_2             ┆ column_3            ┆ column_4 ┆ column_8   │\n",
      "╞════════════╪══════════╪══════════════════════╪═════════════════════╪══════════╪════════════╡\n",
      "│ statistic  ┆ count    ┆ mean                 ┆ std                 ┆ min      ┆ max        │\n",
      "│ CloseLag1  ┆ 4698.0   ┆ 9.434744146445293    ┆ 7.903321463290653   ┆ 1.047    ┆ 44.172     │\n",
      "│ CloseLag2  ┆ 4698.0   ┆ 9.441019795657727    ┆ 7.9087858952326995  ┆ 1.047    ┆ 44.172     │\n",
      "│ CloseLag3  ┆ 4698.0   ┆ 9.447220093656876    ┆ 7.91400686144687    ┆ 1.047    ┆ 44.172     │\n",
      "│ HMLLag1    ┆ 4698.0   ┆ 0.45111323967645806  ┆ 0.43053528722285817 ┆ 0.029    ┆ 4.129      │\n",
      "│ HMLLag2    ┆ 4698.0   ┆ 0.4514563644103873   ┆ 0.43089601442942255 ┆ 0.029    ┆ 4.129      │\n",
      "│ HMLLag3    ┆ 4698.0   ┆ 0.45179480630055346  ┆ 0.43124262085265974 ┆ 0.029    ┆ 4.129      │\n",
      "│ OMCLag1    ┆ 4698.0   ┆ 0.01769391230310771  ┆ 0.37248492041266446 ┆ -3.223   ┆ 3.705      │\n",
      "│ OMCLag2    ┆ 4698.0   ┆ 0.017589186888037466 ┆ 0.3725618641070302  ┆ -3.223   ┆ 3.705      │\n",
      "│ OMCLag3    ┆ 4698.0   ┆ 0.01758407833120477  ┆ 0.372562941912381   ┆ -3.223   ┆ 3.705      │\n",
      "│ VolumeLag1 ┆ 4698.0   ┆ 1846607.4499787143   ┆ 1858696.1408019532  ┆ 52700.0  ┆ 40429700.0 │\n",
      "│ VolumeLag2 ┆ 4698.0   ┆ 1846130.779054917    ┆ 1858810.9684406945  ┆ 52700.0  ┆ 40429700.0 │\n",
      "│ VolumeLag3 ┆ 4698.0   ┆ 1845878.9272030653   ┆ 1858934.5724908514  ┆ 52700.0  ┆ 40429700.0 │\n",
      "│ CloseEMA2  ┆ 4698.0   ┆ 9.441036824180502    ┆ 7.901227922219755   ┆ 1.156    ┆ 43.432     │\n",
      "│ CloseEMA4  ┆ 4698.0   ┆ 9.450132183908048    ┆ 7.900732474686015   ┆ 1.285    ┆ 43.018     │\n",
      "│ CloseEMA8  ┆ 4698.0   ┆ 9.46854576415496     ┆ 7.899496747574999   ┆ 1.382    ┆ 42.696     │\n",
      "│ SPYUp      ┆ 4698.0   ┆ 0.5506598552575565   ┆ 0.49747990726518226 ┆ 0.0      ┆ 1.0        │\n",
      "│ GLDUp      ┆ 4698.0   ┆ 0.5259684972328651   ┆ 0.4993783325710364  ┆ 0.0      ┆ 1.0        │\n",
      "│ VGTUp      ┆ 4698.0   ┆ 0.5576841209025117   ┆ 0.49671426317032225 ┆ 0.0      ┆ 1.0        │\n",
      "│ VBUp       ┆ 4698.0   ┆ 0.5357598978288634   ┆ 0.49877267659502655 ┆ 0.0      ┆ 1.0        │\n",
      "│ IVEUp      ┆ 4698.0   ┆ 0.5340570455512984   ┆ 0.4988918682142226  ┆ 0.0      ┆ 1.0        │\n",
      "│ XLIUp      ┆ 4698.0   ┆ 0.5398041719880801   ┆ 0.49846616338488664 ┆ 0.0      ┆ 1.0        │\n",
      "│ XLUUp      ┆ 4698.0   ┆ 0.5363984674329502   ┆ 0.4987264730981392  ┆ 0.0      ┆ 1.0        │\n",
      "│ SLVUp      ┆ 4698.0   ┆ 0.5163899531715623   ┆ 0.4997844912621346  ┆ 0.0      ┆ 1.0        │\n",
      "│ USOUp      ┆ 4698.0   ┆ 0.511068539804172    ┆ 0.4999306820015263  ┆ 0.0      ┆ 1.0        │\n",
      "└────────────┴──────────┴──────────────────────┴─────────────────────┴──────────┴────────────┘\n",
      "shape: (5, 24)\n",
      "┌───────────┬───────────┬───────────┬─────────┬───┬───────┬───────┬───────┬───────┐\n",
      "│ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ HMLLag1 ┆ … ┆ XLIUp ┆ XLUUp ┆ SLVUp ┆ USOUp │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---     ┆   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64     ┆   ┆ i32   ┆ i32   ┆ i32   ┆ i32   │\n",
      "╞═══════════╪═══════════╪═══════════╪═════════╪═══╪═══════╪═══════╪═══════╪═══════╡\n",
      "│ 32.19     ┆ 31.062    ┆ 30.669    ┆ 1.128   ┆ … ┆ 1     ┆ 0     ┆ 1     ┆ 1     │\n",
      "│ 33.471    ┆ 32.19     ┆ 31.062    ┆ 1.681   ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 33.158    ┆ 33.471    ┆ 32.19     ┆ 1.375   ┆ … ┆ 1     ┆ 0     ┆ 0     ┆ 0     │\n",
      "│ 35.013    ┆ 33.158    ┆ 33.471    ┆ 1.688   ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 0     │\n",
      "│ 33.645    ┆ 35.013    ┆ 33.158    ┆ 1.899   ┆ … ┆ 1     ┆ 1     ┆ 0     ┆ 0     │\n",
      "└───────────┴───────────┴───────────┴─────────┴───┴───────┴───────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "trainStatistics = wtiTrainETF.describe()\n",
    "print(wtiTrainETF.columns)\n",
    "trainStatisticsToPrint = trainStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(trainStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(trainStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(wtiTrainETF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CloseLag1', 'CloseLag2', 'CloseLag3', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'SPYUp', 'GLDUp', 'VGTUp', 'VBUp', 'IVEUp', 'XLIUp', 'XLUUp', 'SLVUp', 'USOUp']\n",
      "Schema({'column': String, 'column_0': String, 'column_2': String, 'column_3': String, 'column_4': String, 'column_8': String})\n",
      "┌────────────┬──────────┬──────────────────────┬──────────────────────┬──────────┬───────────┐\n",
      "│ column     ┆ column_0 ┆ column_2             ┆ column_3             ┆ column_4 ┆ column_8  │\n",
      "╞════════════╪══════════╪══════════════════════╪══════════════════════╪══════════╪═══════════╡\n",
      "│ statistic  ┆ count    ┆ mean                 ┆ std                  ┆ min      ┆ max       │\n",
      "│ CloseLag1  ┆ 157.0    ┆ 1.583496815286624    ┆ 0.2388052963003011   ┆ 1.096    ┆ 2.346     │\n",
      "│ CloseLag2  ┆ 157.0    ┆ 1.5828471337579617   ┆ 0.23851536438187612  ┆ 1.096    ┆ 2.346     │\n",
      "│ CloseLag3  ┆ 157.0    ┆ 1.5820127388535032   ┆ 0.23829673344386126  ┆ 1.096    ┆ 2.346     │\n",
      "│ HMLLag1    ┆ 157.0    ┆ 0.08693630573248408  ┆ 0.05223058853366095  ┆ 0.03     ┆ 0.398     │\n",
      "│ HMLLag2    ┆ 157.0    ┆ 0.08730573248407644  ┆ 0.05217274836594466  ┆ 0.03     ┆ 0.398     │\n",
      "│ HMLLag3    ┆ 157.0    ┆ 0.08761146496815288  ┆ 0.05209331490177502  ┆ 0.03     ┆ 0.398     │\n",
      "│ OMCLag1    ┆ 157.0    ┆ 0.004267515923566881 ┆ 0.06086306426616009  ┆ -0.119   ┆ 0.288     │\n",
      "│ OMCLag2    ┆ 157.0    ┆ 0.004210191082802551 ┆ 0.06089029983030788  ┆ -0.119   ┆ 0.288     │\n",
      "│ OMCLag3    ┆ 157.0    ┆ 0.003891719745222931 ┆ 0.060832639225176156 ┆ -0.119   ┆ 0.288     │\n",
      "│ VolumeLag1 ┆ 157.0    ┆ 1774694.2675159236   ┆ 1436394.6061296004   ┆ 469000.0 ┆ 9514600.0 │\n",
      "│ VolumeLag2 ┆ 157.0    ┆ 1793519.1082802548   ┆ 1441411.6644551635   ┆ 469000.0 ┆ 9514600.0 │\n",
      "│ VolumeLag3 ┆ 157.0    ┆ 1805398.7261146498   ┆ 1439638.7979587486   ┆ 469000.0 ┆ 9514600.0 │\n",
      "│ CloseEMA2  ┆ 157.0    ┆ 1.582611464968153    ┆ 0.23111570666597267  ┆ 1.111    ┆ 2.235     │\n",
      "│ CloseEMA4  ┆ 157.0    ┆ 1.5808598726114649   ┆ 0.22114426949562344  ┆ 1.136    ┆ 2.122     │\n",
      "│ CloseEMA8  ┆ 157.0    ┆ 1.5780191082802548   ┆ 0.20381714628488098  ┆ 1.157    ┆ 1.988     │\n",
      "│ SPYUp      ┆ 157.0    ┆ 0.5668789808917197   ┆ 0.4970926415014129   ┆ 0.0      ┆ 1.0       │\n",
      "│ GLDUp      ┆ 157.0    ┆ 0.5796178343949044   ┆ 0.49519988886944     ┆ 0.0      ┆ 1.0       │\n",
      "│ VGTUp      ┆ 157.0    ┆ 0.5605095541401274   ┆ 0.4979133332299239   ┆ 0.0      ┆ 1.0       │\n",
      "│ VBUp       ┆ 157.0    ┆ 0.4968152866242038   ┆ 0.5015898291312316   ┆ 0.0      ┆ 1.0       │\n",
      "│ IVEUp      ┆ 157.0    ┆ 0.5414012738853503   ┆ 0.49987749601678194  ┆ 0.0      ┆ 1.0       │\n",
      "│ XLIUp      ┆ 157.0    ┆ 0.535031847133758    ┆ 0.5003673319951818   ┆ 0.0      ┆ 1.0       │\n",
      "│ XLUUp      ┆ 157.0    ┆ 0.5668789808917197   ┆ 0.4970926415014129   ┆ 0.0      ┆ 1.0       │\n",
      "│ SLVUp      ┆ 157.0    ┆ 0.535031847133758    ┆ 0.5003673319951818   ┆ 0.0      ┆ 1.0       │\n",
      "│ USOUp      ┆ 157.0    ┆ 0.4840764331210191   ┆ 0.5013455681821809   ┆ 0.0      ┆ 1.0       │\n",
      "└────────────┴──────────┴──────────────────────┴──────────────────────┴──────────┴───────────┘\n",
      "shape: (5, 24)\n",
      "┌───────────┬───────────┬───────────┬─────────┬───┬───────┬───────┬───────┬───────┐\n",
      "│ CloseLag1 ┆ CloseLag2 ┆ CloseLag3 ┆ HMLLag1 ┆ … ┆ XLIUp ┆ XLUUp ┆ SLVUp ┆ USOUp │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---     ┆   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64     ┆   ┆ i32   ┆ i32   ┆ i32   ┆ i32   │\n",
      "╞═══════════╪═══════════╪═══════════╪═════════╪═══╪═══════╪═══════╪═══════╪═══════╡\n",
      "│ 1.628     ┆ 1.638     ┆ 1.579     ┆ 0.059   ┆ … ┆ 0     ┆ 0     ┆ 0     ┆ 1     │\n",
      "│ 1.746     ┆ 1.628     ┆ 1.638     ┆ 0.128   ┆ … ┆ 0     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 1.727     ┆ 1.746     ┆ 1.628     ┆ 0.088   ┆ … ┆ 1     ┆ 1     ┆ 1     ┆ 1     │\n",
      "│ 1.619     ┆ 1.727     ┆ 1.746     ┆ 0.167   ┆ … ┆ 0     ┆ 0     ┆ 1     ┆ 0     │\n",
      "│ 1.599     ┆ 1.619     ┆ 1.727     ┆ 0.098   ┆ … ┆ 0     ┆ 0     ┆ 1     ┆ 1     │\n",
      "└───────────┴───────────┴───────────┴─────────┴───┴───────┴───────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "testStatistics = wtiTestETF.describe()\n",
    "print(wtiTestETF.columns)\n",
    "testStatisticsToPrint = testStatistics.transpose(include_header=True).drop(['column_1', 'column_5', 'column_6', 'column_7'])\n",
    "print(testStatisticsToPrint.schema)\n",
    "with pl.Config(\n",
    "    tbl_rows = 60,\n",
    "    tbl_width_chars = 200,\n",
    "    tbl_cols = -1,\n",
    "    float_precision = 3,\n",
    "    tbl_hide_dataframe_shape = True,\n",
    "    tbl_hide_column_data_types = True):\n",
    "    print(testStatisticsToPrint)\n",
    "\n",
    "# print a few records at the beginning of the DataFrame\n",
    "print(wtiTestETF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names correspond to Numpy array columns: ['CloseLag1', 'CloseLag2', 'CloseLag3', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'SPYUp', 'GLDUp', 'VGTUp', 'VBUp', 'IVEUp', 'XLIUp', 'XLUUp', 'SLVUp', 'USOUp']\n"
     ]
    }
   ],
   "source": [
    "# Standardize features in the training data\n",
    "featureNames = wtiTrainETF.columns\n",
    "print(\"Feature names correspond to Numpy array columns:\",featureNames)\n",
    "scaler = StandardScaler()\n",
    "XTrain = scaler.fit_transform(np.array(wtiTrainETF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names correspond to Numpy array columns: ['CloseLag1', 'CloseLag2', 'CloseLag3', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'SPYUp', 'GLDUp', 'VGTUp', 'VBUp', 'IVEUp', 'XLIUp', 'XLUUp', 'SLVUp', 'USOUp']\n"
     ]
    }
   ],
   "source": [
    "# Standardize features for hold-out test set\n",
    "featureNames = wtiTestETF.columns\n",
    "print(\"Feature names correspond to Numpy array columns:\",featureNames)\n",
    "scaler = StandardScaler()\n",
    "XTest = scaler.fit_transform(np.array(wtiTestETF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training features and target for tree-structured ensemble modeling (XGBoost)\n",
    "X = XTrain  # the full training data set with ETS Up indicators\n",
    "y = yTrain  # the cloned values just computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(all_splits): <class 'list'>  outer list length 5\n",
      "\n",
      "train_0 has 773 with indices from  0 to 772\n",
      "test_0 has 783 with indices from  783 to 1565\n",
      "\n",
      "train_1 has 1556 with indices from  0 to 1555\n",
      "test_1 has 783 with indices from  1566 to 2348\n",
      "\n",
      "train_2 has 2339 with indices from  0 to 2338\n",
      "test_2 has 783 with indices from  2349 to 3131\n",
      "\n",
      "train_3 has 3122 with indices from  0 to 3121\n",
      "test_3 has 783 with indices from  3132 to 3914\n",
      "\n",
      "train_4 has 3905 with indices from  0 to 3904\n",
      "test_4 has 783 with indices from  3915 to 4697\n"
     ]
    }
   ],
   "source": [
    "# Splitting the X (XTrain) and y (yTrain) data \n",
    "# into cross-validation train and test sets\n",
    "# within the Scikit-Learn framework using TimeSeriesSplit\n",
    "# with a gap, for the number of samples to exclude from \n",
    "# the end of each train set and before the next test set.\n",
    "tscv = TimeSeriesSplit(gap=10, n_splits=5)\n",
    "\n",
    "all_splits = list(tscv.split(X, y))\n",
    "train_0, test_0 = all_splits[0]\n",
    "train_1, test_1 = all_splits[1]\n",
    "train_2, test_2 = all_splits[2]\n",
    "train_3, test_3 = all_splits[3]\n",
    "train_4, test_4 = all_splits[4]\n",
    "\n",
    "# examine the objects created for cross-validation splits\n",
    "print(\"type(all_splits):\", type(all_splits), \" outer list length\", len(all_splits))\n",
    "print()\n",
    "print(\"train_0 has\",len(train_0),\"with indices from \",min(train_0),\"to\",max(train_0))\n",
    "print(\"test_0 has\",len(test_0),\"with indices from \",min(test_0),\"to\",max(test_0))\n",
    "print()\n",
    "print(\"train_1 has\",len(train_1),\"with indices from \",min(train_1),\"to\",max(train_1))\n",
    "print(\"test_1 has\",len(test_1),\"with indices from \",min(test_1),\"to\",max(test_1))\n",
    "print()\n",
    "print(\"train_2 has\",len(train_2),\"with indices from \",min(train_2),\"to\",max(train_2))\n",
    "print(\"test_2 has\",len(test_2),\"with indices from \",min(test_2),\"to\",max(test_2))\n",
    "print()\n",
    "print(\"train_3 has\",len(train_3),\"with indices from \",min(train_3),\"to\",max(train_3))\n",
    "print(\"test_3 has\",len(test_3),\"with indices from \",min(test_3),\"to\",max(test_3))\n",
    "print()\n",
    "print(\"train_4 has\",len(train_4),\"with indices from \",min(train_4),\"to\",max(train_4))\n",
    "print(\"test_4 has\",len(test_4),\"with indices from \",min(test_4),\"to\",max(test_4))\n",
    "\n",
    "# to see all indices we can uncomment these statements\n",
    "# print(\"elements of all_splits list of lists,\\n shows index numbers for each the five lists\")\n",
    "# print(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', n_estimators=1000, random_state=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean model.n_estimators = 1000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4947637292464878, 0.02598091670999012)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate a Classification Model Within the Time Series Cross-Validation Design\n",
    "# Prior to executing a full-blown search for the \"best\" classification model, \n",
    "# we test the cross-validation design on a binary classification model, \n",
    "# revising code provided in online documentation for Scikit-Learn: \n",
    "# Time-related feature engineering. In particular,\n",
    "# we define appropriate metrics for assessing classification performance.\n",
    "def evaluate(model, X, y, cv, model_prop=None, model_step=None):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=[\"accuracy\"],\n",
    "        return_estimator=model_prop is not None,\n",
    "    )\n",
    "    if model_prop is not None:\n",
    "        if model_step is not None:\n",
    "            values = [\n",
    "                getattr(m[model_step], model_prop) for m in cv_results[\"estimator\"]\n",
    "            ]\n",
    "        else:\n",
    "            values = [getattr(m, model_prop) for m in cv_results[\"estimator\"]]\n",
    "        print(f\"Mean model.{model_prop} = {np.mean(values)}\")\n",
    "    accuracy = -cv_results[\"test_accuracy\"]\n",
    "\n",
    "    # print used in earlier testing\n",
    "    # print(\n",
    "    #    f\"Mean Accuracy:     {-accuracy.mean():.3f} +/- {accuracy.std():.3f}\\n\"\n",
    "    # )\n",
    "    return (-accuracy.mean(), accuracy.std())\n",
    "    \n",
    "evaluate(model, X, y, cv=tscv, model_prop=\"n_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean model.n_estimators = 1000.0\n",
      "Mean Accuracy:     0.495 +/- 0.026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results from evaluate for the model with default hyperparameter settings\n",
    "accuracyMean, accuracyStd = evaluate(model, X, y, cv=tscv, model_prop=\"n_estimators\")\n",
    "print(\n",
    "        f\"Mean Accuracy:     {accuracyMean:.3f} +/- {accuracyStd:.3f}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:18:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.05637364430976246, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 691, 'subsample': 0.5970606684977592}\n",
      "Best score: 0.5106002554278416\n"
     ]
    }
   ],
   "source": [
    "# Randomized search to find the best set of hyperparameters\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'subsample': uniform(0.5, 1),\n",
    "    'learning_rate': uniform(0.01, 0.1),\n",
    "    'n_estimators': randint(100, 1000),\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=2025)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100, # Number of parameter settings that are sampled.\n",
    "    scoring='accuracy',\n",
    "    cv = TimeSeriesSplit(gap=10, n_splits=5),\n",
    "    random_state=2025,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x15361f500>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Model Classification Performance in the Test Set with \"Best\" hyperparameter settings\n",
    "# final model evaluation\n",
    "finalModel = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=2025,\n",
    "                          max_depth = 3, min_child_weight = 6, subsample = 0.552, learning_rate = 0.103, n_estimators = 110)\n",
    "\n",
    "finalModel.fit(X, y) # fit to the training data\n",
    "ypred = finalModel.predict(XTest) # predictions on the hold-out test data\n",
    "RocCurveDisplay.from_predictions(yTest, ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[31 54]\n",
      " [26 46]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(yTest, ypred))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(yTest, ypred,\n",
    "                              display_labels =[\"0\",\"1\"],\n",
    "                                              cmap = plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix for Returns\")\n",
    "plt.xlabel(\"Predicted Return\")\n",
    "plt.ylabel(\"Actual Return\")\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.36      0.44        85\n",
      "           1       0.46      0.64      0.53        72\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       157\n",
      "   macro avg       0.50      0.50      0.49       157\n",
      "weighted avg       0.51      0.49      0.48       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest, ypred, labels = [\"0\",\"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0485498  0.05014864 0.04153407 0.04655541 0.0437216  0.04683292\n",
      " 0.04472882 0.04442059 0.04525414 0.04386875 0.04124043 0.04550722\n",
      " 0.04161914 0.04029098 0.04140518 0.03696299 0.03331796 0.04327295\n",
      " 0.03996009 0.0403973  0.03649112 0.03022377 0.03888724 0.03480893]\n"
     ]
    }
   ],
   "source": [
    "# Assess and print feature importances\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Features by Importance\n",
    "This completes the exploration of additional features being added to the mix. Now we identify which of those features are most important in classifying the next day's return direction (up or even/down). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names correspond to Numpy array columns: ['CloseLag1', 'CloseLag2', 'CloseLag3', 'HMLLag1', 'HMLLag2', 'HMLLag3', 'OMCLag1', 'OMCLag2', 'OMCLag3', 'VolumeLag1', 'VolumeLag2', 'VolumeLag3', 'CloseEMA2', 'CloseEMA4', 'CloseEMA8', 'SPYUp', 'GLDUp', 'VGTUp', 'VBUp', 'IVEUp', 'XLIUp', 'XLUUp', 'SLVUp', 'USOUp']\n",
      "shape: (24, 2)\n",
      "┌────────────┬────────────┐\n",
      "│ feature    ┆ importance │\n",
      "│ ---        ┆ ---        │\n",
      "│ str        ┆ f32        │\n",
      "╞════════════╪════════════╡\n",
      "│ CloseLag2  ┆ 0.05       │\n",
      "│ CloseLag1  ┆ 0.049      │\n",
      "│ HMLLag1    ┆ 0.047      │\n",
      "│ HMLLag3    ┆ 0.047      │\n",
      "│ VolumeLag3 ┆ 0.046      │\n",
      "│ OMCLag1    ┆ 0.045      │\n",
      "│ OMCLag3    ┆ 0.045      │\n",
      "│ HMLLag2    ┆ 0.044      │\n",
      "│ OMCLag2    ┆ 0.044      │\n",
      "│ VolumeLag1 ┆ 0.044      │\n",
      "│ VGTUp      ┆ 0.043      │\n",
      "│ CloseLag3  ┆ 0.042      │\n",
      "│ CloseEMA2  ┆ 0.042      │\n",
      "│ VolumeLag2 ┆ 0.041      │\n",
      "│ CloseEMA8  ┆ 0.041      │\n",
      "│ CloseEMA4  ┆ 0.04       │\n",
      "│ VBUp       ┆ 0.04       │\n",
      "│ IVEUp      ┆ 0.04       │\n",
      "│ SLVUp      ┆ 0.039      │\n",
      "│ SPYUp      ┆ 0.037      │\n",
      "│ XLIUp      ┆ 0.036      │\n",
      "│ USOUp      ┆ 0.035      │\n",
      "│ GLDUp      ┆ 0.033      │\n",
      "│ XLUUp      ┆ 0.03       │\n",
      "└────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "featureNames = wtiTrainETF.columns\n",
    "print(\"Feature names correspond to Numpy array columns:\",featureNames)\n",
    "\n",
    "# Get feature importances\n",
    "importances = np.round(model.feature_importances_, decimals = 3)\n",
    "\n",
    "# Create Polars DataFrame\n",
    "importanceDF = pl.DataFrame({\"feature\": featureNames, \"importance\": importances})\n",
    "\n",
    "with pl.Config(\n",
    "    tbl_rows = 60):\n",
    "    print(importanceDF.sort(\"importance\", descending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the Modeling Process\n",
    "For subsequent model development, we can retain the top features and then run additional tests with new features using the procedure demonstrated in this analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [yfinance GitHub](https://github.com/ranaroussi/yfinance)\n",
    "* [yfinance Documentation](https://ranaroussi.github.io/yfinance/)\n",
    "* [Polars Online User Guide](https://docs.pola.rs/)\n",
    "* [Build Polars Database](https://www.pyquantnews.com/free-python-resources/build-stock-database-locally-with-polars)\n",
    "* [YouTube. Polars and Time Series: What It Can Do, and How to Overcome Any Limitation](https://www.youtube.com/watch?v=qz-zAHBz6Ks)\n",
    "* [Awesome Quant: Python for Quantiative Finance](https://wilsonfreitas.github.io/awesome-quant/)\n",
    "* [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "* [TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)\n",
    "* [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "* [Hyperparameter Tuning](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "* [Metrics and Scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "* [Introduction to Boosted Trees](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)\n",
    "* [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/index.html)\n",
    "* [XGBoost in Python documentation](https://xgboost-clone.readthedocs.io/en/latest/python/python_intro.html)\n",
    "* [Auto-Sklearn for AutoML in an Scikit-Learn Environment](https://www.automl.org/automl-for-x/tabular-data/auto-sklearn/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Performance Summary ===\n",
      "                      CAGR  Sharpe   MaxDD  Trades  WinRate\n",
      "Label                                                      \n",
      "Aggressive (0.50)   0.0081  0.1677 -0.7978      26   0.4039\n",
      "Conservative (0.70) 0.0292  0.2406 -0.5978      42   0.3105\n",
      "Moderate (0.60)     0.0114  0.1737 -0.7929      31   0.3725\n",
      "\n",
      "Saved equity curves plot to: ./equity_curves.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PA3 Trading Pipeline (EMA 40/80 + Cross-Asset Votes)\n",
    "----------------------------------------------------\n",
    "- Reads daily CSVs for WTI + 9 ETFs (Yahoo-like format or similar) \n",
    "- Builds 40/80 EMA momentum features (1 if EMA40>EMA80 else 0), shifted by 1 day to avoid look-ahead\n",
    "- Cross-asset \"vote share\" -> pseudo probability of up move for the target\n",
    "- Multi-level risk thresholds to convert probability into positions\n",
    "- Backtest on a chosen tradable (USO by default), with simple transaction costs\n",
    "- Outputs performance table and equity curve plots\n",
    "\n",
    "USAGE\n",
    "-----\n",
    "1) Place the CSVs in a folder (by default, same folder where you run this script).\n",
    "   The file names should match the mapping in ASSET_FILES below, or update the mapping.\n",
    "2) Run:\n",
    "   python pa3_trading_pipeline.py\n",
    "\n",
    "You can also import and call `run_pipeline()` from a notebook.\n",
    "\n",
    "DATA EXPECTATION\n",
    "----------------\n",
    "CSV must contain:\n",
    "- A date column named one of: [\"Date\", \"date\", \"DATE\", \"timestamp\"]\n",
    "- A price column named one of: [\"Adj Close\", \"Close\", \"close\", \"adj_close\", \"Price\", \"price\"]\n",
    "All series will be aligned on Date, then features are shifted by 1 day.\n",
    "\n",
    "OUTPUT\n",
    "------\n",
    "- Console performance table for thresholds: 0.50, 0.60, 0.70\n",
    "- Equity curve PNG saved to ./equity_curves.png\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "ASSET_FILES = {\n",
    "    # Target we attempt to predict (WTI) and tradable (USO) + 8 other ETFs from the prompt\n",
    "    \"wti\": \"wti_daily_data.csv\",\n",
    "    \"uso\": \"uso_daily_data.csv\",\n",
    "    \"gld\": \"gld_daily_data.csv\",\n",
    "    \"ive\": \"ive_daily_data.csv\",\n",
    "    \"slv\": \"slv_daily_data.csv\",\n",
    "    \"spy\": \"spy_daily_data.csv\",\n",
    "    \"vb\":  \"vb_daily_data.csv\",\n",
    "    \"vgt\": \"vgt_daily_data.csv\",\n",
    "    \"xli\": \"xli_daily_data.csv\",\n",
    "    \"xlu\": \"xlu_daily_data.csv\",\n",
    "}\n",
    "\n",
    "DATE_COL_CANDIDATES = [\"Date\", \"date\", \"DATE\", \"timestamp\"]\n",
    "PRICE_COL_CANDIDATES = [\"Adj Close\", \"Close\", \"close\", \"adj_close\", \"Price\", \"price\"]\n",
    "\n",
    "EMA_FAST = 40\n",
    "EMA_SLOW = 80\n",
    "\n",
    "# thresholds for multi-level risk\n",
    "RISK_THRESHOLDS = {\n",
    "    \"Aggressive (0.50)\": 0.50,\n",
    "    \"Moderate (0.60)\":   0.60,\n",
    "    \"Conservative (0.70)\": 0.70,\n",
    "}\n",
    "\n",
    "# transaction cost per turnover (one-way) in bps\n",
    "TCOST_BPS = 5  # 0.05% per trade (enter or exit)\n",
    "ANNUALIZATION = 252\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def _find_col(cols: List[str], candidates: List[str]) -> str:\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    raise ValueError(f\"Could not find any of {candidates} in columns: {cols}\")\n",
    "\n",
    "\n",
    "def load_price_series(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Robust loader for a single asset CSV -> DataFrame with ['Date','Price']\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    date_col = _find_col(df.columns.tolist(), DATE_COL_CANDIDATES)\n",
    "    px_col   = _find_col(df.columns.tolist(), PRICE_COL_CANDIDATES)\n",
    "    out = df[[date_col, px_col]].copy()\n",
    "    out.columns = [\"Date\", \"Price\"]\n",
    "    out[\"Date\"] = pd.to_datetime(out[\"Date\"])\n",
    "    out = out.sort_values(\"Date\").dropna().reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_ema_momentum(price_df: pd.DataFrame, span_fast: int, span_slow: int) -> pd.DataFrame:\n",
    "    \"\"\"Add fast/slow EMAs and momentum signal (1 if fast>slow else 0).\"\"\"\n",
    "    p = price_df.copy()\n",
    "    p[\"EMA_fast\"] = p[\"Price\"].ewm(span=span_fast, adjust=False).mean()\n",
    "    p[\"EMA_slow\"] = p[\"Price\"].ewm(span=span_slow, adjust=False).mean()\n",
    "    p[\"mom_sig\"]  = (p[\"EMA_fast\"] > p[\"EMA_slow\"]).astype(int)\n",
    "    return p\n",
    "\n",
    "\n",
    "def align_assets(assets: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Merge by Date into a wide DataFrame with hierarchical columns:\n",
    "       ('wti','Price'), ('wti','mom_sig'), ...\"\"\"\n",
    "    # build list of dfs with prefixed columns\n",
    "    dfs = []\n",
    "    for name, df in assets.items():\n",
    "        tmp = df[[\"Date\", \"Price\", \"EMA_fast\", \"EMA_slow\", \"mom_sig\"]].copy()\n",
    "        tmp.columns = pd.MultiIndex.from_product([[name], tmp.columns], names=[\"asset\", \"field\"])\n",
    "        dfs.append(tmp.set_index((name, \"Date\")))\n",
    "        # ^ we temporarily set index to the (name,'Date') to avoid col collisions; will reindex by Date later\n",
    "\n",
    "    # Reindex and merge on the true Date: use the first asset's Date as a base, then outer join all\n",
    "    # Simpler approach: merge sequentially on Date by resetting index\n",
    "    base = None\n",
    "    for name, df in assets.items():\n",
    "        tmp = df[[\"Date\", \"Price\", \"EMA_fast\", \"EMA_slow\", \"mom_sig\"]].copy()\n",
    "        tmp.columns = [\"Date\", f\"{name}_Price\", f\"{name}_EMA_fast\", f\"{name}_EMA_slow\", f\"{name}_mom_sig\"]\n",
    "        if base is None:\n",
    "            base = tmp\n",
    "        else:\n",
    "            base = pd.merge(base, tmp, on=\"Date\", how=\"outer\")\n",
    "\n",
    "    base = base.sort_values(\"Date\").reset_index(drop=True)\n",
    "    return base\n",
    "\n",
    "\n",
    "def shift_features(df: pd.DataFrame, feature_cols: List[str], shift_by: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"Shift features to ensure we only use t-1 info to trade at t.\"\"\"\n",
    "    out = df.copy()\n",
    "    for c in feature_cols:\n",
    "        out[c] = out[c].shift(shift_by)\n",
    "    return out\n",
    "\n",
    "\n",
    "def backtest(returns: pd.Series, prob: pd.Series, threshold: float, tcost_bps: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"Simple long-only backtest with thresholded probability.\n",
    "       - position[t] = 1 if prob[t] >= threshold else 0\n",
    "       - portfolio_ret[t] = position[t-1] * returns[t] - tcost * turnover[t]\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"ret\": returns, \"prob\": prob}).copy()\n",
    "    df[\"signal\"] = (df[\"prob\"] >= threshold).astype(int)\n",
    "    # use previous day's position for today's PnL\n",
    "    df[\"position\"] = df[\"signal\"].shift(1).fillna(0.0)\n",
    "\n",
    "    # turnover when position changes today (based on today's signal vs yesterday's position)\n",
    "    df[\"prev_pos\"] = df[\"position\"].shift(1).fillna(0.0)\n",
    "    df[\"turnover\"] = (df[\"position\"] - df[\"prev_pos\"]).abs()\n",
    "\n",
    "    tcost = tcost_bps / 10000.0  # convert bps -> decimal\n",
    "    df[\"strategy_ret\"] = df[\"position\"] * df[\"ret\"] - tcost * df[\"turnover\"]\n",
    "\n",
    "    df[\"equity\"] = (1.0 + df[\"strategy_ret\"]).cumprod()\n",
    "    return df\n",
    "\n",
    "\n",
    "def perf_summary(trade_df: pd.DataFrame, label: str) -> Dict[str, float]:\n",
    "    \"\"\"Compute key metrics: CAGR, Sharpe, MaxDD, Trades, WinRate.\"\"\"\n",
    "    daily = trade_df[\"strategy_ret\"].dropna()\n",
    "    if len(daily) == 0:\n",
    "        return {\"Label\": label, \"CAGR\": np.nan, \"Sharpe\": np.nan, \"MaxDD\": np.nan, \"Trades\": 0, \"WinRate\": np.nan}\n",
    "\n",
    "    # CAGR\n",
    "    start_equity = 1.0\n",
    "    end_equity = float(trade_df[\"equity\"].iloc[-1])\n",
    "    num_days = len(daily)\n",
    "    cagr = end_equity ** (ANNUALIZATION / num_days) - 1 if num_days > 0 else np.nan\n",
    "\n",
    "    # Sharpe (daily -> annual)\n",
    "    sharpe = daily.mean() / (daily.std() + 1e-12) * np.sqrt(ANNUALIZATION) if daily.std() > 0 else np.nan\n",
    "\n",
    "    # Max Drawdown\n",
    "    eq = trade_df[\"equity\"].fillna(1.0).values\n",
    "    peak = np.maximum.accumulate(eq)\n",
    "    dd = (eq / peak - 1.0).min()\n",
    "\n",
    "    # Trades & Win rate (a \"trade\" defined as a 0->1 entry)\n",
    "    entries = (trade_df[\"turnover\"] > 0) & (trade_df[\"position\"] == 1.0)\n",
    "    num_trades = int(entries.sum())\n",
    "    # daily wins\n",
    "    wins = (daily > 0).mean()\n",
    "\n",
    "    return {\"Label\": label, \"CAGR\": cagr, \"Sharpe\": sharpe, \"MaxDD\": dd, \"Trades\": num_trades, \"WinRate\": wins}\n",
    "\n",
    "\n",
    "def run_pipeline(\n",
    "    data_dir: Path = Path(\".\"),\n",
    "    target_symbol: str = \"wti\",    # we predict WTI direction\n",
    "    trade_symbol: str = \"uso\",     # we trade USO as a proxy (or 'wti' if you prefer)\n",
    "    thresholds: Dict[str, float] = None,\n",
    "    tcost_bps: float = TCOST_BPS,\n",
    "    ema_fast: int = EMA_FAST,\n",
    "    ema_slow: int = EMA_SLOW,\n",
    "    beta_target_boost: float = 1.0,  # weight target's own momentum in prob calc\n",
    "    plot_file: Path = Path(\"./equity_curves.png\"),\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        results_table: performance summary for each threshold (rows)\n",
    "        equity_curves: DataFrame of equity curves for each threshold (cols)\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = RISK_THRESHOLDS\n",
    "\n",
    "    # 1) Load assets\n",
    "    assets = {}\n",
    "    for name, fname in ASSET_FILES.items():\n",
    "        fpath = data_dir / fname\n",
    "        if not fpath.exists():\n",
    "            raise FileNotFoundError(f\"Missing file: {fpath}. Update ASSET_FILES or place CSVs accordingly.\")\n",
    "        df = load_price_series(fpath)\n",
    "        df = compute_ema_momentum(df, ema_fast, ema_slow)\n",
    "        assets[name] = df\n",
    "\n",
    "    # 2) Align by Date\n",
    "    wide = align_assets(assets)\n",
    "\n",
    "    # Identify columns\n",
    "    price_cols = [c for c in wide.columns if c.endswith(\"_Price\")]\n",
    "    mom_cols   = [c for c in wide.columns if c.endswith(\"_mom_sig\")]\n",
    "\n",
    "    # Compute returns on the tradable\n",
    "    trade_price_col = f\"{trade_symbol}_Price\"\n",
    "    if trade_price_col not in wide.columns:\n",
    "        raise ValueError(f\"Trade symbol '{trade_symbol}' not loaded. Available: {price_cols}\")\n",
    "    wide[\"ret_trade\"] = wide[trade_price_col].pct_change()\n",
    "\n",
    "    # 3) Build probability based on cross-asset votes (yesterday -> today)\n",
    "    #    Use all ETFs *except* the target itself to form votes; optionally include target's own momentum with beta\n",
    "    target_mom_col = f\"{target_symbol}_mom_sig\"\n",
    "    vote_cols = [c for c in mom_cols if c != target_mom_col]\n",
    "    # shift by 1-day to ensure no look-ahead\n",
    "    feat_cols = vote_cols + [target_mom_col]\n",
    "    wide = shift_features(wide, feat_cols, shift_by=1)\n",
    "\n",
    "    # prob = (votes + beta * target_mom) / (N + beta)\n",
    "    N = len(vote_cols)\n",
    "    wide[\"votes\"] = wide[vote_cols].sum(axis=1)\n",
    "    wide[\"prob\"] = (wide[\"votes\"] + beta_target_boost * wide[target_mom_col]) / (N + beta_target_boost)\n",
    "\n",
    "    # 4) Backtest for thresholds\n",
    "    results = []\n",
    "    equity_curves = pd.DataFrame({\"Date\": wide[\"Date\"]})\n",
    "\n",
    "    for label, thr in thresholds.items():\n",
    "        bt = backtest(wide[\"ret_trade\"], wide[\"prob\"], thr, tcost_bps=tcost_bps)\n",
    "        summ = perf_summary(bt, label)\n",
    "        results.append(summ)\n",
    "        equity_curves[label] = bt[\"equity\"].values\n",
    "\n",
    "    results_table = pd.DataFrame(results).set_index(\"Label\").sort_index()\n",
    "\n",
    "    # 5) Plot equity curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for label in thresholds.keys():\n",
    "        plt.plot(equity_curves[\"Date\"], equity_curves[label], label=label)\n",
    "    plt.title(f\"Equity Curves (Trade: {trade_symbol.upper()}, Prob: Cross-Asset EMA Votes)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Equity\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_file, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    return results_table, equity_curves\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run with defaults, assuming CSVs live in current directory\n",
    "    results, curves = run_pipeline()\n",
    "    # Pretty print\n",
    "    print(\"\\n=== Performance Summary ===\")\n",
    "    print(results.to_string(float_format=lambda x: f\"{x:,.4f}\"))\n",
    "    print(\"\\nSaved equity curves plot to: ./equity_curves.png\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.331543px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
